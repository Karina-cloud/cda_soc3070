<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Análisis de Datos Categóricos (SOC3070)</title>
    <meta charset="utf-8" />
    <meta name="author" content="  Mauricio Bucca  Profesor Asistente, Sociología UC" />
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" href="gentle-r.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Análisis de Datos Categóricos (SOC3070)
## Clase #11
### <br> Mauricio Bucca<br> Profesor Asistente, Sociología UC
### <a href="https://github.com/mebucca">github.com/mebucca</a>

---


class: inverse, center, middle

#Regresión Logística, inferencia

---
##Configuración

--

&lt;br&gt;

- Tenemos `\(y_{1}, \dots y_{n}\)` son `\(n\)` variables independientes con distribución `\(\text{Bernoulli}(p_{i})\)`


--

- `\(\mathbb{E}(y_{i} \mid x_{i1}, \dots,x_{ik}) = \mathbb{P}(y_{i}=1 \mid x_{i1}, \dots,x_{ik}) = p_{i}\)` 

&lt;br&gt;
--

donde, 


`$$\ln \frac{p_{i}}{1 - p_{i}} = \beta_{0} + \beta_{1} x_{i1} + \dots + \beta_{k} x_{ik}$$`

---
##Configuración

&lt;br&gt;

- Tenemos `\(y_{1}, \dots y_{n}\)` son `\(n\)` variables independientes con distribución `\(\text{Bernoulli}(p_{i})\)`


- `\(\mathbb{E}(y_{i} \mid x_{i1}, \dots,x_{ik}) = \mathbb{P}(y_{i}=1 \mid x_{i1}, \dots,x_{ik}) = p_{i}\)` 

&lt;br&gt;

donde, 

.content-box-blue[
`$$\underbrace{\ln \frac{p_{i}}{1 - p_{i}}}_{\text{Link logit}(p_{i})} = \overbrace{\beta_{0} + \beta_{1} x_{i1} + \dots + \beta_{k} x_{ik}}^{\text{Predictor lineal  } \eta_{i}}$$`
]

--

- .bold[Inferencia]: ¿que podemos decir sobre `\(\hat{\beta}_{0},\hat{\beta}_{1}, \dots, \hat{\beta}_{k}\)`  (o cualquier producto de éstos) más allá de nuestra muestra?

---
class: inverse, center, middle

## Inferencia estadística para regresión logística (y GLMs)


---
## Inferencia acerca de parámetros del modelo

- Los coeficientes de un GLM son estimados via MLE.
--
 Un ML "estimate" `\(\hat{\theta}\)` tiene las siguientes propiedades:

--

.img-right[![MLE_prop](unbiased_consistent.png)]


.pull-left[
- Es .bold[consistente]: `\(\hat{\theta} \xrightarrow{p} \theta\)`. Es decir, en la medida que `\(n \to \infty\)`, el  estimador `\(\hat{\theta}\)` tiende en probabilidad a `\(\theta\)`, el valor verdadero del parámetro. 
]
.pull-right[
]

--

.pull-left[
- Es .bold[insesgado]: `\(\mathbb{E}(\hat{\theta}) = \theta\)`.
]
.pull-right[
]

--

.pull-left[
- Distribuye .bold[asintónticamente normal]: `\(\hat{\theta} \xrightarrow{d} \mathcal{N}(\theta, \frac{\sigma_{\theta}}{\sqrt{n}})\)`. Es decir, no solo converge al valor verdadero, sino que converge rápidamente ( `\(1/\sqrt{n}\)` ).
]
.pull-right[
]

--

Notar que `\(\frac{\sigma_{\theta}}{\sqrt{n}}\)` es el "standard error" (SE) de `\(\theta\)`.

&lt;style type="text/css"&gt;
.pull-right ~ * { clear: unset; }
.pull-right + * { clear: both; }
&lt;/style&gt;

---
## Inferencia acerca de parámetros del modelo: intervalos de confianza

Dado que `\(\hat{\theta} \sim \mathcal{N}(\theta, \frac{\sigma_{\theta}}{\sqrt{n}})\)` ...

&lt;br&gt;
--

podemos construir un intervalo de confianza de la siguiente manera:

`$$(1 - \alpha) \text{ CI}_{\hat{\theta}} = \hat{\theta} \pm \Phi^{-1}(\alpha/2) \cdot SE_{\hat{\theta}}$$`
&lt;br&gt;
--

Ejemplo, un intervalo al 95% de confianza está dado por:

`$$95\% \text{ CI}_{\hat{\theta}} = \hat{\theta} \pm 1.96 \cdot  \frac{\sigma_{\theta}}{\sqrt{n}}$$`

---
## Inferencia acerca de parámetros del modelo: tests

--

.middle[
.center[
![tests](ttest_gelman.png)

]
]

---
## Inferencia acerca de parámetros del modelo: ejemplo empírico



Retomando nuestro modelo de clases anteriores: `\(\ln \frac{p_{i}}{ 1 - p_{i}}    = \beta_{0} + \beta_{1}\text{male}_{i} + \beta_{2}\text{ym}_{i}\)`

--


```
## everaffair_d ~ factor(sex) + ym
```

```
##                    Estimate Std. Error   z value     Pr(&gt;|z|)
## (Intercept)     -1.71395429 0.20633183 -8.306786 9.832929e-17
## factor(sex)male  0.22157111 0.19064190  1.162237 2.451391e-01
## ym               0.05842959 0.01727402  3.382513 7.182590e-04
```

--

.content-box-blue[
.bold[Calculemos un IC al 95% para efecto el de "years of marriage" sobre el logit de ser infiel:] `\(\beta_{2}\)`
]

--


```r
beta2 &lt;- summary(logit_affairs_sex_ym)$coefficients["ym","Estimate"]
se_beta2 &lt;- summary(logit_affairs_sex_ym)$coefficients["ym","Std. Error"]
ci_beta2 &lt;- beta2 + c(-1.96,1.96)*se_beta2; ci_beta2
```

```
## [1] 0.02457252 0.09228667
```

--


```r
confint(logit_affairs_sex_ym)
```

```
## Waiting for profiling to be done...
```

```
##                       2.5 %      97.5 %
## (Intercept)     -2.12990424 -1.31985336
## factor(sex)male -0.15199429  0.59625678
## ym               0.02479755  0.09260135
```


---
## Inferencia acerca de parámetros del modelo: ejemplo empírico

--

.content-box-blue[
.bold[Calculemos ahora un IC al 95% para efecto multiplicativo de "years of marriage" sobre las odds de ser infiel:] `\(e^{\beta_{2}}\)`
]

--

![michael](michael.gif)

--

¿Cuál es la sampling distribution de una función de nuestro estimate?

---
class: inverse, center, middle

## Delta Method


---
## Delta Method

[Series de Taylor](https://en.wikipedia.org/wiki/Taylor_series) permiten aproximar el valor de una función `\(g(x)\)` -- potencialmente compleja -- usando una  una suma infinita de términos. Aquí la primera expansión de la serie:

--

$$g(x) \approx g(c) + g^{'}(c)(x - c) $$
--

.pull-left[
Ejemplo: 
.content-box-blue[
- `\(g(x) = \ln(x)\)`

- `\(c=5\)`

- `\(g^{'}(x) = \frac{d\ln(x)}{dx}= \frac{1}{x}\)`

]
]

--

.pull-right[
Aproximación via serie de Taylor centrada en 5
.content-box-yellow[
`\begin{align}
\ln(x) &amp;\approx \ln(5) + \frac{1}{5}(x - 5) \\
       &amp;\approx 1.609438 + 0.2 \cdot (x - 5) \\
       &amp; .
\end{align}`
]
]

--

- Cuando `\(x=5.5\)`, `\(\ln(5.5) = 1.704748\)`. Aproximación: `\(1.609438 + 0.2 \cdot 0.5 = 1.709438\)`

--


- Cuando `\(x=10\)`, `\(\ln(10) = 2.302585\)`. Aproximación: `\(1.609438 + 0.2 \cdot 5 = 2.609438\)`

&lt;style type="text/css"&gt;
.pull-right ~ * { clear: unset; }
.pull-right + * { clear: both; }
&lt;/style&gt;

---
## Delta Method

Aplicando `\(g(x) \approx g(c) + g^{'}(c)(x - c)\)` a un estimador `\(\hat{\theta}\)` (variable) y donde `\(\theta\)` es el valor verdadero del parámetro (constante), obtenemos:

&lt;br&gt;

`$$g(\hat{\theta}) \approx g(\theta) + g^{'}(\theta)(\hat{\theta} - \theta)$$`
&lt;br&gt;
--

So what?

&lt;br&gt;
--


- .bold[¿Cual es la distribución de] `\(g(\hat{\theta})\)`?


---
## Delta Method

Dado
`$$g(\hat{\theta}) \approx g(\theta) + g^{'}(\theta)(\hat{\theta} - \theta)$$`

--

- `\(\mathbb{E}(\hat{\theta})\)`:

--


`\begin{align}
\mathbb{E}[g(\hat{\theta})] &amp;\approx \mathbb{E}[ g(\theta) + g^{'}(\theta)(\hat{\theta} - \theta) ] \\ \\
&amp;\approx \mathbb{E}[ g(\theta)] + g^{'}(\theta)\mathbb{E}[(\hat{\theta} - \theta) ]  \\ \\
&amp;\approx \mathbb{E}[ g(\theta)] + g^{'}(\theta)(\mathbb{E}[\hat{\theta}] - \theta) \\ \\
&amp;\approx \mathbb{E}[ g(\theta)] + g^{'}(\theta)(\theta - \theta) \\ \\
&amp;\approx \mathbb{E}[ g(\theta)] = g(\theta)  
\end{align}`


---
## Delta Method

Dado
`$$g(\hat{\theta}) \approx g(\theta) + g^{'}(\theta)(\hat{\theta} - \theta)$$`
--

- `\(\mathbb{Var}(\hat{\theta})\)`:


--

`\begin{align}
 &amp;\approx \mathbb{Var}[ g(\theta) + g^{'}(\theta)(\hat{\theta} - \theta) ] \\ \\
&amp;\approx \mathbb{Var}[g(\theta) + g^{'}(\theta)\hat{\theta}   -  g^{'}(\theta)\theta] \\ \\
&amp;\approx   [g^{'}(\theta)]^{2} \mathbb{Var}[\hat{\theta}]   
\end{align}`

&lt;br&gt;
--

- `\(\sqrt{\mathbb{Var}[g(\hat{\theta})]}: SE_{g(\hat{\theta})}\)`: 

`$$\approx g^{'}(\theta) SE_{\hat{\theta}}$$`   

---
## Delta Method

Se puede mostrar tambien que `\(g(\hat{\theta})\)` distribuye normal.

&lt;br&gt;
--

En particular:

.content-box-blue[
`$$g(\hat{\theta}) \sim \mathcal{N}\bigg(\mu=g(\theta), \sigma=g^{'}(\theta) SE_{\hat{\theta}} \bigg)$$` 
]
---
## Delta Method: ejemplo empírico

--

Retomando nuestro modelo: `\(\ln \frac{p_{i}}{ 1 - p_{i}}    = \beta_{0} + \beta_{1}\text{male}_{i} + \beta_{2}\text{ym}_{i}\)`


--

.content-box-blue[
.bold[Calculemos  IC al 95% para efecto multiplicativo de "years of marriage" sobre las odds de ser infiel:] `\(e^{\beta_{2}}\)`
]

--

Usando `\(g(\hat{\theta}) \sim \mathcal{N}\big(g(\theta), g^{'}(\theta) \cdot SE_{\hat{\theta}} \big)\)` obtenemos...

.img-bottom-right[
![d](easy.gif)
]



---
## Delta Method: ejemplo empírico


Retomando nuestro modelo: `\(\ln \frac{p_{i}}{ 1 - p_{i}}    = \beta_{0} + \beta_{1}\text{male}_{i} + \beta_{2}\text{ym}_{i}\)`



.content-box-blue[
.bold[Calculemos IC al 95% para efecto multiplicativo de "years of marriage" sobre las odds de ser infiel:] `\(e^{\beta_{2}}\)`
]


Usando `\(g(\hat{\theta}) \sim \mathcal{N}\big(g(\theta), g^{'}(\theta) \cdot SE_{\hat{\theta}} \big)\)` obtenemos...


--
.pull-left[
.content-box-blue[
- `\(g(\hat{\beta}_{2}) = e^{\hat{\beta}_{2}}\)`

- `\(\mathbb{E}(e^{\hat{\beta}_{2}}) = e^{\beta_{2}}\)`

- `\(g^{'}(\beta_{2}) =  e^{\beta_{2}}\)` 

- `\(SE_{e^{\hat{\beta}_{2}}} = e^{\beta_{2}} \cdot SE_{\hat{\beta}_{2}}\)`
]
]

--

.pull-right[
.content-box-yellow[
`$$e^{\hat{\beta}_{2}} \sim \mathcal{N}\big(e^{\beta_{2}}, e^{\beta_{2}} \cdot SE_{\hat{\beta}_{2}} \big)$$`
]

Remplazar el parámetro "verdadero" por nuestro "estimate" en muestra.

]



---
## Delta Method: ejemplo empírico


```
## everaffair_d ~ factor(sex) + ym
```

```
##                    Estimate Std. Error   z value     Pr(&gt;|z|)
## (Intercept)     -1.71395429 0.20633183 -8.306786 9.832929e-17
## factor(sex)male  0.22157111 0.19064190  1.162237 2.451391e-01
## ym               0.05842959 0.01727402  3.382513 7.182590e-04
```

--


```r
expbeta2 &lt;- exp(beta2); expbeta2
```

```
## [1] 1.06017
```

```r
se_expbeta2_delta &lt;- expbeta2*se_beta2; se_expbeta2_delta
```

```
## [1] 0.0183134
```

```r
ci_expbeta2_delta &lt;- expbeta2 + c(-1.96,1.96)*se_expbeta2_delta; ci_expbeta2_delta
```

```
## [1] 1.024276 1.096065
```


&lt;style type="text/css"&gt;
.pull-right ~ * { clear: unset; }
.pull-right + * { clear: both; }
&lt;/style&gt;

---
## Delta Method: ejemplo empírico


```
## everaffair_d ~ factor(sex) + ym
```

```
##                    Estimate Std. Error   z value     Pr(&gt;|z|)
## (Intercept)     -1.71395429 0.20633183 -8.306786 9.832929e-17
## factor(sex)male  0.22157111 0.19064190  1.162237 2.451391e-01
## ym               0.05842959 0.01727402  3.382513 7.182590e-04
```

--
&lt;br&gt;

Versión automática usando función `deltamethod` en paquete `msm`:


```r
library(msm)
se_expbeta2_delta &lt;- deltamethod(g=~exp(x1), mean=beta2, cov=(se_beta2)^2); se_expbeta2_delta 
```

```
## [1] 0.0183134
```

```r
#intervalo de confianza
ci_expbeta2_delta &lt;- expbeta2 + c(-1.96,1.96)*se_expbeta2_delta; ci_expbeta2_delta
```

```
## [1] 1.024276 1.096065
```


---
## Delta Method: ejemplo empírico

Continuando con nuestro modelo: `\(\ln \frac{p_{i}}{ 1 - p_{i}}    = \beta_{0} + \beta_{1}\text{male}_{i} + \beta_{2}\text{ym}_{i}\)`

--

.content-box-blue[
.bold[Calculemos ahora IC al 95% para el Average Marginal Effect de"years of marriage" sobre la probabilidad de ser infiel]
]


--

Usando `\(g(\hat{\theta}) \sim \mathcal{N}\big(g(\theta), g^{'}(\theta) \cdot SE_{\hat{\theta}} \big)\)`, sólo necesitamos...

.img-bottom-right[
![d](easy.gif)
]

---
## Delta Method: ejemplo empírico

Continuando con nuestro modelo: `\(\ln \frac{p_{i}}{ 1 - p_{i}}    = \beta_{0} + \beta_{1}\text{male}_{i} + \beta_{2}\text{ym}_{i}\)`



.content-box-blue[
.bold[Calculemos ahora IC al 95% para el Average Marginal Effect de"years of marriage" sobre la probabilidad de ser infiel]
]



Usando `\(g(\hat{\theta}) \sim \mathcal{N}\big(g(\theta), g^{'}(\theta) \cdot SE_{\hat{\theta}} \big)\)`, sólo necesitamos...



- `\(g(\hat{\beta}_{2}) = \frac{1}{N} \sum^{N}_{i=1} \frac{\partial p_{i}}{\partial \text{ym}}= \frac{1}{N} \sum^{N}_{i=1}  \hat{\beta}_{2} \cdot \Bigg(\frac{1}{1 + e^{-(\beta_{0} + \beta_{1}\text{male}_{i} + \beta_{2}\text{ym}_{i} )}}\Bigg) \Bigg(1 - \frac{1}{1 + e^{-(\beta_{0} + \beta_{1}\text{male}_{i} + \beta_{2}\text{ym}_{i})}}\Bigg)\)`

- `\(\mathbb{E}(\frac{1}{N} \sum^{N}_{i=1} \frac{\partial p_{i}}{\partial \text{ym}}) =  \dots\)`

- `\(g^{'}(\frac{1}{N} \sum^{N}_{i=1} \frac{\partial p_{i}}{\partial \text{ym}}) =  \dots\)` 

--

.img-right-bottom[
![scream](scream.gif)
]

---
class: inverse, center, middle

## Simulation and Resampling Methods


---
## Métodos de simulación y re-muestreo para inferencia estadística

&lt;br&gt;
--

- Incluso para estimadores muy simples es difícil (o imposible) determinar la distribución de la muestra.

--

- Cuando es posible, los resultados se basan en supuestos sobre distribución, comportamientos asintóticos y aproximaciones que no siempre se cumplen.  

--

- Los métodos de simulación y re-muestreo ofrecen una alternativa cuando no se dispone de soluciones analíticas (una formula conocida).

--

- Estos métodos son computacionalmente intensivos, lo que los hacía inviables en el pasado pero no actualmente.

--

- Dos métodos especialmente útiles:

 - Monte Carlo Simulation
 
 - Boostrapping

---
class: inverse, center, middle

## Monte Carlo Simulation

---
## Monte Carlo Simulation


![casino](mc_casino.jpg)
---
## Monte Carlo Simulation


.bold[Intuición:]

--

- Estimamos un modelo y tenemos una cierta "cantidad de interés" (estimate)

--


- No conocemos la distribución de nuestro estimate a través de infinitas muestras porque sólo tenemos una muestra. 


--

- Tampoco tenemos conocimiento teórico sobre la distribución de nuestro estimate.

--

- Sin embargo, "conocemos" la distribución de nuestros datos y sus parámetros, por tanto, podemos generar muestras aleatorias.

--

- Podemos observar y estudiar el comportamiento de nuestro estimate en estas muestras generadas aleatoriamente.

---
## Monte Carlo Simulation

.bold[Esquema del algoritmo]:

--

1. Asume una la distribución los datos.


--

2. Usando la distribución asumida y los parámetros estimados (en nuestro caso, `\(y \sim \text{Binomial}(\hat{p} = \text{logit}^{-1}(X\hat{\theta}))\)` ), genera una muestra aleatoriad de datos `\(y_{m}\)`

--

3. Regresiona `\(y_{m}\)` y `\(X\)` para obtener el estimate `\(\hat{\theta}_{m}\)` 

--

4. Repite los pasos 2 y 3  M veces (número grande).

--

5. El conjunto de M resultados obtenidos corresponde a la "Monte Carlo distribution" del estimate.

--

6. Evalúa la distribución del estimate (SE,CI, etc) o de cualquier cantidad derivada de éste.


---
## Monte Carlo Simulation: ejemplo empírico

Siguiendo con `\(\ln \frac{p_{i}}{ 1 - p_{i}}    = \beta_{0} + \beta_{1}\text{male}_{i} + \beta_{2}\text{ym}_{i}\)`, 
--

.content-box-blue[
.bold[Calculemos un IC al 95% para efecto el de "years of marriage" sobre el logit de ser infiel:] `\(\beta_{2}\)`
]

--


```r
# Escribir una función que ejecute re-sampling y la estimación
mc_beta2  &lt;- function(x) {
  p_hat   &lt;- predict(logit_affairs_sex_ym, type="response")
  y_m     &lt;- rbinom(n=length(p_hat),size=1,prob=p_hat)
  logit_m &lt;- glm(y_m ~ factor(affairsdata$sex) + affairsdata$ym, family=binomial(link="logit"))
  beta2_m &lt;- logit_m$coefficients[3]
  return(ym=beta2_m)
}
# Iterar función y almacenar resultados 
nreps = 2000
betas2_mc &lt;- replicate(nreps,mc_beta2()); head(betas2_mc)
```

```
## affairsdata$ym affairsdata$ym affairsdata$ym affairsdata$ym affairsdata$ym 
##     0.05146268     0.05560868     0.06016580     0.04846167     0.02811260 
## affairsdata$ym 
##     0.05555154
```

---
## Monte Carlo Simulation: ejemplo empírico

--

.pull-left[

```r
betasall_mc &lt;- sim(logit_affairs_sex_ym, n.sims=2000)@coef
betasall_mc %&gt;% head(4)
```

```
##      (Intercept) factor(sex)male         ym
## [1,]   -1.698518    -0.004230119 0.06917410
## [2,]   -1.741403     0.389068043 0.05508404
## [3,]   -1.513140     0.202690967 0.03834317
## [4,]   -1.622648     0.152309530 0.04851111
```

```r
se_beta2_mc &lt;- sd(betasall_mc[,"ym"]); se_beta2_mc
```

```
## [1] 0.01700079
```

```r
ci_beta2_mc &lt;- 
  quantile(betasall_mc[,"ym"], p=c(0.025,0.975))
  ci_beta2_mc
```

```
##       2.5%      97.5% 
## 0.02620450 0.09114127
```
]

--

.pull-right[
![](class_11_files/figure-html/unnamed-chunk-14-1.png)&lt;!-- --&gt;
]

---
## Monte Carlo Simulation: ejemplo empírico

.content-box-blue[
¿Un IC al 95% para efecto el de "years of marriage" como .bold["odds ratio"]: `\(e^{\beta_{2}}\)`? 
]

Simulando ...
--

.img-right-bottom2[
![easy](easy.gif)
]

--


```r
betasall_mc &lt;- sim(logit_affairs_sex_ym, n.sims=2000)@coef
expbetasall_mc &lt;- exp(betasall_mc)
expbetasall_mc %&gt;% head()
```

```
##      (Intercept) factor(sex)male       ym
## [1,]   0.1848239       0.9555037 1.054114
## [2,]   0.1618621       1.4213703 1.063487
## [3,]   0.1325152       1.3378590 1.084000
## [4,]   0.1999550       1.0681191 1.060567
## [5,]   0.2556474       1.4339205 1.020179
## [6,]   0.1227470       1.1098605 1.104933
```


---
## Monte Carlo Simulation: ejemplo empírico

--

.pull-left[

```r
se_exbeta2_mc &lt;- sd(expbetasall_mc[,"ym"]); se_exbeta2_mc
```

```
## [1] 0.01851656
```

```r
ci_expbeta2_mc &lt;- 
  quantile(expbetasall_mc[,"ym"], p=c(0.025,0.975))
  ci_expbeta2_mc
```

```
##     2.5%    97.5% 
## 1.023863 1.097732
```
]

--

.pull-right[
![](class_11_files/figure-html/unnamed-chunk-17-1.png)&lt;!-- --&gt;
]

---
## Monte Carlo Simulation: ejemplo empírico


.content-box-blue[
.bold[Calculemos ahora IC al 95% para el Average Marginal Effect de"years of marriage" sobre la probabilidad de ser infiel]
]


--

Simulando ...

.img-bottom-right[
![easy](easy.gif)
]


---
## Monte Carlo Simulation: ejemplo empírico


.content-box-blue[
.bold[Calculemos ahora IC al 95% para el Average Marginal Effect de"years of marriage" sobre la probabilidad de ser infiel]
]

--


Simulando ...



```r
mc_ame_beta2  &lt;- function(x) {
  p_hat   &lt;- predict(logit_affairs_sex_ym, type="response")
  y_m     &lt;- rbinom(n=length(p_hat),size=1,prob=p_hat)
  logit_m &lt;- glm(y_m ~ factor(affairsdata$sex) + affairsdata$ym, family=binomial(link="logit"))
  p_hat_m &lt;- predict(logit_m, type="response")
  beta2_m &lt;- logit_m$coefficients[3]
  me_m    &lt;-  beta2_m*p_hat_m*(1-p_hat_m) 
  ame_m   &lt;- mean(me_m)
  return(ame_m)
}
# Iterar función y almacenar resultados 
nreps = 2000
ame_ym_mc &lt;- replicate(nreps,mc_ame_beta2()); head(ame_ym_mc,4)
```

```
## [1] 0.008883067 0.014971353 0.008348255 0.011654252
```

---
## Monte Carlo Simulation: ejemplo empírico


.pull-left[

```r
p_hat   &lt;- predict(logit_affairs_sex_ym, type = "response")
me_ym   &lt;- beta2*p_hat*(1-p_hat)
ame_ym  &lt;- mean(me_ym); ame_ym
```

```
## [1] 0.01070277
```

```r
se_ame_ym_bs &lt;- sd(ame_ym_mc); se_ame_ym_bs 
```

```
## [1] 0.003076942
```

```r
ci_ame_ym_mc &lt;- 
  quantile(ame_ym_mc, p=c(0.025,0.975))
  ci_ame_ym_mc
```

```
##        2.5%       97.5% 
## 0.004690266 0.016804841
```
]

--

.pull-right[
![](class_11_files/figure-html/unnamed-chunk-20-1.png)&lt;!-- --&gt;
]

---

&lt;br&gt;

.bold[¿Y si ni siquiera conocemos la distribución de nuestros datos?]
--
.bold[¿Y si nuestro modelo no es paramétrico?]

.pull-left[
![boots](rambo.jpg)

]

--

.pull-right[
![boots](boots.jpg)
]

---
class: inverse, center, middle

## Bootstrap Method 

---
## Bootstrap Method 

.bold[Intuición:]

--

- Estimamos un modelo y tenemos una cierta "cantidad de interés" (estimate)

--


- No conocemos la distribución nuestro estimate a través de infinitas muestras porque sólo tenemos una muestra. 

--

- Tampoco tenemos conocimiento teórico sobre la distribución de nuestro estimate.

--

- Podemos tomar muestras de nuestra muestra, preservando cualquier distribución desconocida subyacente.

--

- Podemos observar y estudiar el comportamiento de nuestro estimate en estas muestras de nuestras muestras.

---
## Bootstrap Method 

.bold[Muestrando desde la muestra:]

¿Cuántas muestras podemos tomar (con reemplazo) a partir de nuestra muestra?
--
 .bold[Respuesta]: `\(n^n\)`

&lt;br&gt;
--

`$$\text{muestra} : \left[\begin{array}{@{}c@{}}
    1 \\
    2 \\
    3 
    \end{array} \right]$$`

&lt;br&gt;
--

`$$\text{posibles muestras de la muesta:} \left[\begin{array}{@{}c@{}} 
    1 \\
    1 \\
    1 
    \end{array} \right] 
    \text{ o}  \left[\begin{array}{@{}c@{}} 
    1 \\
    1 \\
    2 
    \end{array} \right] 
    \text{ o}  \left[\begin{array}{@{}c@{}} 
    1 \\
    3 \\
    2 
    \end{array} \right] 
    \text{ o}  \left[\begin{array}{@{}c@{}} 
    3 \\
    1 \\
    2 
    \end{array} \right] 
    \text{ o}  \left[\begin{array}{@{}c@{}} 
    3 \\
    3 \\
    3 
    \end{array} \right]  ...$$`

---
## Bootstrap Method

.bold[Esquema del algoritmo] (Bootstrap no paramétrico):

--

1. Asume que la distribución empírica del los datos refleja la distribución de probabilidad de las variables de interés.

--

2. A partir de la muestra obtenén una muestra aleatoria del mismo tamaño que la muestra original (N), con reemplazo:  `\((y_{b},X_{b})\)`

--

3. Regresiona `\(y_{b}\)` y `\(X_{b}\)` para obtener el estimate `\(\hat{\theta}_{b}\)` 

--

4. Repite los pasos 2 y 3 un gran número de veces B.

--

5. El conjunto de B resultados obtenidos corresponde a la "Bootstrap distribution" del estimate.

--

6. Evalúa la distribución del estimate (SE,CI, etc) o de cualquier cantidad derivada de éste.

---
## Bootstrap Method: ejemplo empírico 

Siguiendo con `\(\ln \frac{p_{i}}{ 1 - p_{i}}    = \beta_{0} + \beta_{1}\text{male}_{i} + \beta_{2}\text{ym}_{i}\)`, 
--

.content-box-blue[
.bold[Calculemos un IC al 95% para efecto el de "years of marriage" sobre el logit de ser infiel:] `\(\beta_{2}\)`
]

--


```r
# Escribir una función que ejecute re-sampling y la estimación
bs_beta2  &lt;- function(x) {
  data_b  &lt;- sample_n(affairsdata,size=nrow(affairsdata),replace=TRUE)
  logit_b &lt;- glm(everaffair_d ~ factor(sex) + ym, family=binomial(link="logit"), data=data_b)
  beta2_b &lt;- logit_b$coefficients[3]
  return(beta2_b)
}

# Iterar función y almacenar resultados 
nreps = 2000
betas2_bs &lt;- replicate(nreps,bs_beta2()); head(betas2_bs)
```

```
##         ym         ym         ym         ym         ym         ym 
## 0.07743217 0.07533579 0.04380318 0.07109119 0.07599709 0.04344652
```

---
## Bootstrap Method: ejemplo empírico 

.pull-left[

```r
se_beta2_bs &lt;- sd(betas2_bs)
se_beta2_bs
```

```
## [1] 0.01648759
```

```r
ci_beta2_bs &lt;- 
  quantile(betas2_bs, p=c(0.025,0.975))
  ci_beta2_bs
```

```
##       2.5%      97.5% 
## 0.02585743 0.09117889
```
]

--

.pull-right[
![](class_11_files/figure-html/unnamed-chunk-23-1.png)&lt;!-- --&gt;
]

---
## Bootstrap Method: ejemplo empírico 

.content-box-blue[
¿Un IC al 95% para efecto el de "years of marriage" como .bold["odds ratio"]: `\(e^{\beta_{2}}\)`? 
]

--

Bootstrapeando ...


.img-bottom-right[
![easy](easy.gif)
]


---
## Bootstrap Method: ejemplo empírico 

.content-box-blue[
¿Un IC al 95% para efecto el de "years of marriage" como .bold["odds ratio"]: `\(e^{\beta_{2}}\)`? 
]


Bootstrapeando ...



```r
# Escribir una función que ejecute re-sampling y la estimación
bs_expbeta2  &lt;- function(x) {
  data_b  &lt;- sample_n(affairsdata,size=nrow(affairsdata),replace=TRUE)
  logit_b &lt;- glm(everaffair_d ~ factor(sex) + ym, family=binomial(link="logit"), data=data_b)
  expbeta2_b &lt;- exp(logit_b$coefficients[3])
  return(expbeta2_b)
}

# Iterar función y almacenar resultados 
nreps = 2000 
expbetas2_bs &lt;- replicate(nreps,bs_expbeta2()); head(expbetas2_bs)
```

```
##       ym       ym       ym       ym       ym       ym 
## 1.063435 1.041132 1.061592 1.063071 1.041011 1.056147
```

---
## Bootstrap Method: ejemplo empírico 

.pull-left[

```r
se_expbeta2_bs &lt;- sd(expbetas2_bs)
se_expbeta2_bs
```

```
## [1] 0.01763901
```

```r
ci_expbeta2_bs &lt;- 
  quantile(expbetas2_bs, p=c(0.025,0.975))
  ci_expbeta2_bs
```

```
##     2.5%    97.5% 
## 1.026531 1.096067
```
]

--

.pull-right[
![](class_11_files/figure-html/unnamed-chunk-26-1.png)&lt;!-- --&gt;
]

---
## Bootstrap Method: ejemplo empírico

.content-box-blue[
.bold[Calculemos ahora IC al 95% para el Average Marginal Effect de"years of marriage" sobre la probabilidad de ser infiel]
]

--

Bootstrapeando ...

.img-bottom-right[
![easy](easy.gif)
]


---
## Bootstrap Method: ejemplo empírico

.content-box-blue[
.bold[Calculemos ahora IC al 95% para el Average Marginal Effect de"years of marriage" sobre la probabilidad de ser infiel]
]


Bootstrapeando ...


```r
# Escribir una función que ejecute re-sampling y la estimación
bs_ame_ym  &lt;- function(x) {
  data_b   &lt;- sample_n(affairsdata,size=nrow(affairsdata),replace=TRUE)
  logit_b  &lt;- glm(everaffair_d ~ factor(sex) + ym, family=binomial(link="logit"), data=data_b)
  beta2_b  &lt;- logit_b$coefficients[3]
  p_hat_b  &lt;- predict(logit_b, type = "response")
  me_ym_b   &lt;- beta2_b*p_hat_b*(1-p_hat_b)
  return(ame_ym_b = mean(me_ym_b))
}

# Iterar función y almacenar resultados 
nreps = 2000 
ame_ym_bs &lt;- replicate(nreps,bs_ame_ym()); head(ame_ym_bs)
```

```
## [1] 0.017796591 0.009229415 0.011059382 0.009350072 0.011967101 0.012932793
```


---
## Bootstrap Method: ejemplo empírico

.pull-left[

```r
p_hat   &lt;- predict(logit_affairs_sex_ym, type = "response")
me_ym   &lt;- beta2*p_hat*(1-p_hat)
ame_ym  &lt;- mean(me_ym); ame_ym
```

```
## [1] 0.01070277
```

```r
se_ame_ym_bs &lt;- sd(ame_ym_bs)
se_ame_ym_bs
```

```
## [1] 0.003004656
```

```r
ci_ame_ym_bs &lt;- 
  quantile(ame_ym_bs, p=c(0.025,0.975))
  ci_ame_ym_bs
```

```
##        2.5%       97.5% 
## 0.004705823 0.016534069
```
]

--

.pull-right[
![](class_11_files/figure-html/unnamed-chunk-29-1.png)&lt;!-- --&gt;
]

---
## Bootstrap Method: más ... 



.pull-left[
![](class_11_files/figure-html/unnamed-chunk-31-1.png)&lt;!-- --&gt;
]

--

.pull-right[
![](class_11_files/figure-html/unnamed-chunk-32-1.png)&lt;!-- --&gt;
]

---
class: inverse, center, middle

.huge[
**Hasta la próxima clase. Gracias!**
]

&lt;br&gt;
Mauricio Bucca &lt;br&gt;
https://mebucca.github.io/ &lt;br&gt;
github.com/mebucca
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": true,
"slideNumberFormat": "%current%"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>

---
title: "Análisis de Datos Categóricos (SOC3070)"
subtitle: "Clase #11"
author: "<br> Mauricio Bucca<br> Profesor Asistente, Sociología UC"
date: "[github.com/mebucca](https://github.com/mebucca)"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: ["default","default-fonts","gentle-r.css"]
    df_print: default
    nature:
      ratio: 16:9
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: true
      slideNumberFormat: "%current%"
editor_options: 
  chunk_output_type: console
---
class: inverse, center, middle
#Ajuste y comparación de modelos

---
class: inverse, center, middle

##Deviance

---
## Comparación entre modelos

```{r,  include=TRUE, echo=FALSE, warning=FALSE, message=FALSE}
# load data on extra-marital affairs from package "Ecdat"
library("Ecdat")
library("viridis")
library("tidyverse")
library("modelr")
library("cowplot")
library("margins")
library("rsample")
library("arm")


theme_set(theme_cowplot())

data(Fair)
affairsdata <- Fair %>% as_tibble()

# create a binary variable indicating wether persons has ever had an affair
affairsdata <- affairsdata %>% 
  mutate(everaffair = case_when(nbaffairs == 0 ~ "Never", nbaffairs > 0 ~ "At least once") ) %>%
  # map into 0/1 code
  mutate(everaffair_d = case_when(nbaffairs == 0 ~ 0, nbaffairs > 0 ~ 1))
```


Retomando nuestro modelo de clases anteriores: $\ln \frac{p_{i}}{ 1 - p_{i}}    = \beta_{0} + \beta_{1}\text{male}_{i} + \beta_{2}\text{ym}_{i}$

--

```{r,echo=FALSE}
# modelo 1: sex + years of marriage
logit_affairs_sex_ym1 <-  glm(everaffair_d ~ ym,family=binomial(link="logit"), data=affairsdata)
summary(logit_affairs_sex_ym1)$coefficients
print(paste0("log-likelihood: ",round(logLik(logit_affairs_sex_ym1),3),
             " Deviance: ", round(summary(logit_affairs_sex_ym1)$deviance,3) ))
print(paste0("AIC: ", round(summary(logit_affairs_sex_ym1)$aic,3),
             " BIC: ", round(BIC(logit_affairs_sex_ym1),3) ))

```

<br>
--

¿Cómo saber si este modelo "complejo" (2 predictores) tiene un desempeño sustancialmente mejor un sub-modelo, más simple)

```{r,echo=FALSE}
# modelo 0: sex 
logit_affairs_sex_ym0 <-  glm(everaffair_d ~  ym + factor(sex) , family=binomial(link="logit"), data=affairsdata)
summary(logit_affairs_sex_ym0)$coefficients
print(paste0("log-likelihood: ",round(logLik(logit_affairs_sex_ym0),3),
             " Deviance: ", round(summary(logit_affairs_sex_ym0)$deviance,3) ))
print(paste0("AIC: ", round(summary(logit_affairs_sex_ym0)$aic,3),
             " BIC: ", round(BIC(logit_affairs_sex_ym0),3) ))
```


---
## Likelihood del modelo

Recordar que cada observación es una manifestación de una variable Bernoulli:


$Y_{i} \sim \text{Bernoulli}(p_{i}) \quad \text{ es decir } \quad \mathbb{P}(Y_{i}= y) = p_{i}^{y}(1-p_{i})^{1-y} \quad \text{ donde } \quad y \in \{0,1\}$

--

Por tanto, la probabilidad de observar estos datos es descrita por la siguiente función:

$$\mathbb{P}(y_{1}, \dots, y_{1}) = \Pi_{i=1}^{n} p_{i}^{y_{i}}(1-p_{i})^{1-y_{i}}$$
<br>
--

En consecuencia, la .bold[likelihood function] de $p_{i}$ es:

$$\mathcal{L}(p_{i} \mid y_{1}, \dots, y_{1}) = \Pi_{i=1}^{n} p_{i}^{y_{i}}(1-p_{i})^{1-y_{i}}$$

--

y la .bold[log likelihood function] de $p_{i}$ es:


$$\ell\ell(p_{i} \mid y_{1}, \dots, y_{1}) = \sum_{i=1}^{n} \bigg( y_{i} \ln p_{i} + (1-y_{i}) \ln(1-p_{i}) \bigg)$$


donde: $p_{i} =\frac{1}{1 + e^{-(\beta_{0} + \beta_{1}x_{i} + \dots \beta_{k}x_{k}})}$


---
## Likelihood del modelo


.bold[Implentación en] `R`:
 
```{r, include=TRUE, echo=TRUE, warning=FALSE, message=FALSE}

ll <- function(b0,b1,b2) {
  y = affairsdata$everaffair_d
  eta = b0  + b1*affairsdata$ym + b2*I(1*(affairsdata$sex=="male"))
  ell = sum( y*log(1/(1 + exp(-eta))) +  (1-y)*log(1 - (1/(1 + exp(-eta)))))
  return(ll = ell)
}

```

--

```{r}
ll(b0=1.2,b1=0.7,b2=1)
```

--

```{r}
ll(b0=1.2,b1=0.7,b2=0)
```
---
## Likelihood del modelo M

En nuestro ejemplo empírico: $\ln \frac{p_{i}}{ 1 - p_{i}}    = \beta_{0} + \beta_{1}\text{male}_{i} + \beta_{2}\text{ym}_{i}$
--

.pull-left[
```{r,echo=FALSE}
# modelo 1: sex + years of marriage
logit_affairs_sex_ym1 <-  glm(everaffair_d ~ ym,family=binomial(link="logit"), data=affairsdata)
summary(logit_affairs_sex_ym1)$coefficients[,1:2]
print(paste0("log-likelihood: ",round(logLik(logit_affairs_sex_ym1),3)))
```
]
.pull-right[
```{r,echo=FALSE}
# modelo 0: sex 
logit_affairs_sex_ym0 <-  glm(everaffair_d ~  ym + factor(sex) , family=binomial(link="logit"), data=affairsdata)
summary(logit_affairs_sex_ym0)$coefficients[,1:2]
print(paste0("log-likelihood: ",round(logLik(logit_affairs_sex_ym0),3)))
```
]

--

```{r}
# log-likelihood modelos
ll_m0 <- ll(b0=-1.608587,b1=0.058822,b2=0)
ll_m1 <- ll(b0=-1.71395429,b1=0.05842959,b2=0.22157111)
print(paste0("ll modelo 0: ",ll_m0,"ll modelo 1: ",ll_m1))

```

--

El modelo más complejo es "mejor" que el modelo más simple, pero ...
--
 ¿Es .bold[signicativamente mejor]?
 

---
## Likelihood del model "saturado"

$$\newcommand{\vect}[1]{\boldsymbol{#1}}$$

- .bold[Modelo saturado] ( $M_S$ ): es el modelo que asume que cada observación tiene sus propios parámetros, es decir, estima  $n$-parámetros, $\vect{\beta}_{S}$. El modelo saturado describe perfectamente los datos: mejor "fit" posible, pero el menos "parsimonioso".

--

  - La log-likelihood de este modelo es $\ell\ell_{S}: \ell\ell(\vect{\beta}_{S} | \vect{y})$, donde $\ell\ell_{S}$ es mayor que la likelihood de cualquier otro modelo para los mismos datos, asumiendo misma distribución y misma función de enlace.
  
<br>
--

```{r, warning=FALSE}
# modelo saturado 
id = seq(1:length(affairsdata$everaffair_d))
logit_affairs_sex_sat <-  glm(everaffair_d ~ factor(id) , family=binomial(link="logit"), 
                              data=affairsdata)

ll_sat <- logLik(logit_affairs_sex_sat); ll_sat
```

--

Prácticamente, $\ell\ell_{S}=0$. ¿Por qué?

---
## Likelihood del model "nulo"


- .bold[Modelo nulo] ( $M_0$ ): es el modelo que asume que cada observación tiene sus propios parámetros, es decir, estima  $n$-parámetros, $\vect{\beta}_{0}$. El modelo saturado describe perfectamente los datos: mejor "fit" posible, pero el menos "parsimonioso".

--

  - La log-likelihood de este modelo es $\ell\ell_{0}: \ell\ell(\beta_{0} | \vect{y})$, donde $\ell\ell_{0}$ es menor que la likelihood de cualquier otro modelo.
  
<br>
--

```{r, warning=FALSE}
# modelo saturado 
id = seq(1:length(affairsdata$everaffair_d))
logit_affairs_sex_sat <-  glm(everaffair_d ~ factor(id) , family=binomial(link="logit"), 
                              data=affairsdata)

ll_sat <- logLik(logit_affairs_sex_sat); ll_sat
```

--

Prácticamente, $\ell\ell_{S}=0$. ¿Por qué?


---
## Likelihood ratio

\begin{align}
&\text{LR}: \frac{\mathcal{L}_{S}}{\mathcal{L}_{M}}  \implies  \\ \\
&\log \text{LR} : \log \frac{\mathcal{L}_{S}}{\mathcal{L}_{M}} = \log\mathcal{L}_{S} - \log \mathcal{L}_{M} 
\end{align}


\begin{align}
\text{Deviance} &: 2 \log \text{LR} \\
&: 2 (\log\mathcal{L}_{S} - \log \mathcal{L}_{M} )
\end{align}


---
## Null Deviance y Residual Deviance

\begin{align}
\log \bigg(\frac{\mathcal{L_S}}{} \bigg)
\end{align}


Los modelos nulo y saturado sirven como referencia para evaluar el ajuste de un modelo. 

- $\text{Deviance}: -2(\ell\ell_{M} - \ell\ell_{S})$, o "residual deviance"

- $\text{Null Deviance}: -2(\ell\ell_{M} - \ell\ell_{0})$, o "residual deviance"

---
class: inverse, center, middle

.huge[
**Hasta la próxima clase. Gracias!**
]

<br>
Mauricio Bucca <br>
https://mebucca.github.io/ <br>
github.com/mebucca





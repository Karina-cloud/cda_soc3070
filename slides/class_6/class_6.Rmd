---
title: "Análisis de Datos Categóricos (SOL3070)"
subtitle: "Clase #6"
author: "<br> Mauricio Bucca<br> Profesor Asistente, Sociología UC"
date: "[github.com/mebucca](https://github.com/mebucca)"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: ["default","default-fonts","gentle-r.css"]
    df_print: default
    nature:
      ratio: 16:9
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: true
      slideNumberFormat: "%current%"
editor_options: 
  chunk_output_type: console
---

class: inverse, center, middle

#Tablas de Contingencia
## Medidas de asociación

---
##  Asociación en tablas de contingencia 

Las variables de una tabla de contingencia están asociadas si la distribución condicional de las variables es distinta de su distribución marginal. Formalmente, 

<br>

- $f_{Y \mid X}(Y \mid X) \neq f_{Y}(Y)$

y por tanto,

- $f_{X \mid Y}(X \mid Y) \neq f_{X}(X)$


---
##  Asociación en tablas de contingencia 

```{r,  include=TRUE, echo=FALSE, warning=FALSE, message=FALSE}
library("Ecdat")
data(Fair)
affairsdata <- Fair %>% as_tibble()

# create a binary variable indicating wether persons has ever had an affair
affairsdata <- affairsdata %>% 
	mutate(everaffair = case_when(nbaffairs == 0 ~ "Never", nbaffairs > 0 ~ "At least once") )

ctable <- affairsdata %>% with(table(sex,everaffair))
```

Continuando con nuestro ejemplo,

.pull-left[
$f(\text{everaffair} \mid \text{sex})$
```{r}
prop.table(ctable,1)
```


$f(\text{everaffair})$
```{r}
prop.table(apply(ctable,2,sum))
```

]

--

.pull-right[
Al parece que los hombres tienen una mayor probabilid que las mujeres de haber tenido un "affair".

En lo que sigue vamos a usar este ejemplo para estudiar:

- Diferentes formas de cuantificar la asociación entre variables de una tabla de contingencia

- Evaluar si las diferencias observadas son o no más sustanciales de lo se esperaría debido al mero azar.
]

---
### Diferencia de proporciones

- Supongamos que tenemos una tabla de contingencia 2-ways que cruza las variables binarias $X$ (independiente) y $Y$ (dependiente).  Éxito se codifica con valor 1 y el fracaso con el valor cero.

- Para detectar la asociación necesitamos medir diferencias en la distribución de $Y$ condicional en $X$

--
La diferencia de proporciones cuantifica estas diferencias de la siguiente manera:

$$\delta = \mathbb{P}(Y=1 \mid X=1) - \mathbb{P}(Y=1 \mid X=0)$$
--

Noten que $\delta \in [-1,1]$ donde $\delta=0$ indica proporciones iguales. 

--

Volviendo a nuestro ejemplo, $\hat{p}_{M}$, llamemos y a la proporción de hombres que han tenido una aventura y $\hat{p}_{W}$ a la proporción de mujeres que han tenido una aventura. La diferencia de proporciones se define simplemente como:

\begin{align}
  \hat{\delta} &= \hat{p}_{M} - \hat{p}_{W} \\ \\
  &= 0.273 - 0.229 \\ \\
  &= 0.044
\end{align}

---
### Diferencia de proporciones

Dos consideraciones importantes:

1) La diferencia de proporciones debe estar adecuadamente definida en términos de una variable dependiente y otra independiente. La razón es que, en general:

$$\mathbb{P}(Y=1 \mid X=1) - \mathbb{P}(Y=1 \mid X=0) \neq  \mathbb{P}(X=1 \mid Y=1) - \mathbb{P}(X=1 \mid Y=0)$$

--

En nuestro ejemplo:

```{r}
prop.table(ctable,2)
```

Si tratamos género como variable independiente y definimos "mujeres" como la categoría de éxito, la diferencia en las proporciones es $\delta = 0.48 - 0.54 = -0.06$. 

---
### Diferencia de proporciones

2) La diferencia de proporciones es una estadística intuitiva y fácil de interpretar, pero por sí sola puede ser engañosa cuando las proporciones son ambas cercanas a cero. Consideremos los dos casos hipotéticos siguientes:

\begin{align}
  \text{Caso 1: } p_{1a}=0.410 \text{ and } p_{1b}=0.401  \\ \\
  \text{aquí: } \delta_{1} = 0.009
\end{align}

--
y

\begin{align}
  \text{Caso 2: } p_{2a}=0.010 \text{ and } p_{2b}=0.001  \\ \\
  \text{aquí: } \delta_{2} = 0.009
\end{align}

--
¿Problemas? En el caso 1 ambas porciones son, según todos los indicios, casi idénticas. En el caso 2, sin embargo, ambas proporciones son similares en términos absolutos, por muy diferentes en términos relativos: $0.010$ es 10 veces mayor $0.001$.


---
### Riesgo Relativo (RR)

En casos como el descrito anteriormente el ratio entre las proporciones es una estadística más relevante. El riesgo relativo se define como:

$$RR = \frac{\mathbb{P}(Y=1 \mid X=1)}{\mathbb{P}(Y=1 \mid X=0)}$$

Notar que $RR \in [0,\infty+]$, donde $RR=1$ indica igualdad de proporciones. 

<br>
--

En nuestro ejemplo, el riesgo relativo estimado es:

\begin{align}
  \hat{RR} &= \frac{\hat{p}_{M}}{\hat{p}_{W}} \\ \\
  &= \frac{0.273}{0.229} = 1.19214
\end{align}

--

La proporción de infidelidad entre los hombres es aproximadamente un 20% mayor que entre las mujeres. 

---
### Riesgo Relativo (RR)

Tres consideraciones importantes:

1) Al igual que la diferencia de proporciones, el riesgo relativo debe definirse adecuadamente en términos de una variable dependiente y otra independiente. En general:

$$\frac{\mathbb{P}(Y=1 | X=1)}{\mathbb{P}(Y=1 | X=0)} \neq  \frac{\mathbb{P}(X=1 | Y=1) }{\mathbb{P}(X=1 | Y=0)}$$

--

En nuestro ejemplo:

```{r}
prop.table(ctable,2)
```

Si tratamos género como variable independiente y definimos "mujeres" como la categoría de éxito, la diferencia en las proporciones es $RR = 0.48/0.54 = 0.89$. 

---
### Riesgo Relativo (RR)

2) El riesgo relativo depende que categoría definimos cómo "éxito". En general, 


$$\frac{\mathbb{P}(Y=1 | X=1)}{\mathbb{P}(Y=1 | X=0)} \neq \frac{\mathbb{P}(Y=0 | X=0)}{\mathbb{P}(Y=0 | X=1)}$$
--

En nuestro ejemplo:

.pull-left[
ratio proporción infidelidad H/M
\begin{align}
  \frac{\hat{p}_{M}}{\hat{p}_{W}} &= \frac{0.273}{0.229} \\ \\
   &= 1.19214
\end{align}
]

.pull-left[
ratio proporción fidelidad M/H
\begin{align}
  \frac{1-\hat{p}_{W}}{1-\hat{p}_{M}} &= \frac{0.771}{0.727} \\ \\
   &= 1.060523
\end{align}
]


---
### Riesgo Relativo (RR)

3)  Si una de las proporciones involucradas en el cálculo es demasiado pequeña, el $RR$ puede tomar valores arbitrariamente grandes o arbitrariamente pequeños. 

<br>

  - Ejemplo: $0.7/0.005 = 140$

--

  - En estos casos la definición de la variable dependiente/independiente, y de la la categoría de éxito afectan         
radicalmente el resultado:

    - invirtiendo la categoría de exito: $0.3/0.9 = 0.3$
    
    - invirtiendo la variable dependiente: $0.009/0.768=0.012$, u otros, dependiente de categoría de éxito
  
--

  - Problema muy común cuando se trabaja con eventos con muy baja prevalencia (ej, suicidio, covid, etc.)

---
### Odds Ratio

<br>

- Odds ratio ( $\theta$ ) es una medida fundamental de asociación. 

- Parámetro de interés en el modelo más importante de datos categóricos: regresión logística.

- $\theta$ está formulada para tablas de 2-por-2, pero también puede calcularse para tablas de mayor dimensión: toda tabla $n$-ways, $I \times J$, puede ser re-escrita como  $(I-1) \times (J-1) \times (n-1)$ tablas de 2-por-2.

---
#### Odds

La Odds Ratio es el ratio de dos "odds", donde las "odds" una variable binaria $Y$ se definen como: 

<br>

\begin{align}
  \text{odds} &= \frac{\mathbb{P}(Y=1)}{1-\mathbb{P}(Y=1)} \\ \\
              &=  \frac{p}{1-p}
\end{align}

<br>
--

Por ejemplo, si $Y$ tiene una probabilidad de éxito $p=0.75$, las odds de éxito son $\text{odds}=\frac{0.75}{0.25} = 3$. 

- Esto significa que el éxito es 3 veces más probable que el fracaso.


---
#### Odds

las Odds son funciones de probabilidades y, por lo tanto, las probabilidades también pueden expresarse en función de las odds. Formalmente:

$$p = \frac{\text{odds}}{1 + \text{odds}}$$

--

Siguiendo con ejemplo anterior, si sabemos que las odds de éxito son igual a 3, entonces la probabilidad ( $p$ ) de éxito es:

.pull-left[
\begin{align}
p &= \frac{3}{1 + 3} \\ \\
  &= 0.75
\end{align}
]

--

.pull-right[

.content-box-grey[
.tiny[.bold[Derivación]:
\begin{align}
  \text{odds} &= \frac{p}{1-p}  \text{  } \\ \\
  \text{odds} &= \frac{1}{\frac{1}{p} - 1}  \\ \\
  \frac{1}{p} &= \frac{1}{\text{odds}} + 1  \\  \\
  \frac{1}{p} &= \frac{1 + \text{odds}}{\text{odds}}  \\ \\
           p  &= \frac{\text{odds}}{1 + \text{odds}}
\end{align}
]
]
]

---
### Odds Ratio

Las .bold[odds] resumen la distribución de una sola variable binaria. Para medir la asociación entre dos de estas variables en una tabla podemos calcular la .bold[odds *ratio*]. 

--

Si $X$ e $Y$ son las variables independiente y dependiente, la distribución condicional $f(Y \mid X)$ se puede resumir con dos .bold[odds]:

\begin{align}
  \text{odds}_{0} &=  \frac{\mathbb{P}(Y=1 | X=0) }{1 - \mathbb{P}(Y=1 | X=0) } \quad \text{y} \\ \\
  \text{odds}_{1} &=  \frac{\mathbb{P}(Y=1 | X=1) }{1 - \mathbb{P}(Y=1 | X=1) } 
\end{align}

--

El .bold[odds *ratio*], por tanto, es:

\begin{align}
  \theta &= \frac{\text{odds}_{1}}{\text{odds}_{0}} \\ \\\
\end{align}


---
### Odds Ratio

Volviendo a nuestro ejemplo,

```{r,echo=FALSE}
prop.table(ctable,1)
```

Si $\hat{p}_{M}$ es la proporción de hombres que han tenido una aventura y $\hat{p}_{W}$ es la proporción de mujeres que han tenido una aventura. 


\begin{align}
  \hat{\theta} = \frac{\text{odds}_{M}}{\text{odds}_{W}} &= \\
         &= \frac{\hat{p}_{M}/(1 - \hat{p}_{M})}{\hat{p}_{W}/(1 - \hat{p}_{W})} \\ \\
         &= \frac{0.273/0.727}{0.229/0.771} \\ \\
         &= \frac{0.38}{0.30} \\ \\
         &= 1.27
\end{align}


---
class: inverse, center, middle

.huge[
**Hasta la próxima clase. Gracias!**
]

<br>
Mauricio Bucca <br>
https://mebucca.github.io/ <br>
github.com/mebucca





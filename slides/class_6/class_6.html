<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Análisis de Datos Categóricos (SOL3070)</title>
    <meta charset="utf-8" />
    <meta name="author" content="  Mauricio Bucca  Profesor Asistente, Sociología UC" />
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" href="gentle-r.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Análisis de Datos Categóricos (SOL3070)
## Clase #6
### <br> Mauricio Bucca<br> Profesor Asistente, Sociología UC
### <a href="https://github.com/mebucca">github.com/mebucca</a>

---


class: inverse, center, middle

#Tablas de Contingencia
## Medidas de asociación

---
##  Asociación en tablas de contingencia 

Las variables de una tabla de contingencia están asociadas si la distribución condicional de las variables es distinta de su distribución marginal. Formalmente, 

&lt;br&gt;

- `\(f_{Y \mid X}(Y \mid X) \neq f_{Y}(Y)\)`

y por tanto,

- `\(f_{X \mid Y}(X \mid Y) \neq f_{X}(X)\)`


---
##  Asociación en tablas de contingencia 



Continuando con nuestro ejemplo,

.pull-left[
`\(f(\text{everaffair} \mid \text{sex})\)`

```r
prop.table(ctable,1)
```

```
##         everaffair
## sex      At least once     Never
##   female     0.2285714 0.7714286
##   male       0.2727273 0.7272727
```


`\(f(\text{everaffair})\)`

```r
prop.table(apply(ctable,2,sum))
```

```
## At least once         Never 
##      0.249584      0.750416
```

]

--

.pull-right[
Al parece que los hombres tienen una mayor probabilidad que las mujeres de haber tenido un "affair".

En lo que sigue vamos a usar este ejemplo para estudiar:

- Diferentes formas de cuantificar la asociación (o la ausencia de la misma) entre variables de una tabla de contingencia

- Evaluar si las diferencias observadas son o no más sustanciales de lo se esperaría debido al mero azar.
]

---
class: inverse, center, middle

## Medidas de Asociación

---
## Diferencia de proporciones

- Supongamos que tenemos una tabla de contingencia 2-ways que cruza las variables binarias `\(X\)` (independiente) y `\(Y\)` (dependiente).  Éxito se codifica con valor 1 y el fracaso con el valor 0.

- Para detectar la asociación necesitamos medir diferencias en la distribución de `\(Y\)` condicional en `\(X\)`

--
La diferencia de proporciones cuantifica estas diferencias de la siguiente manera:

`$$\delta = \mathbb{P}(Y=1 \mid X=1) - \mathbb{P}(Y=1 \mid X=0)$$`
--

Noten que `\(\delta \in [-1,1]\)` donde `\(\delta=0\)` indica proporciones iguales. 

--

Volviendo a nuestro ejemplo, `\(\hat{p}_{H}\)`, llamemos y a la proporción de hombres que han tenido una aventura y `\(\hat{p}_{M}\)` a la proporción de mujeres que han tenido una aventura. La diferencia de proporciones se define simplemente como:

`\begin{align}
  \hat{\delta} &amp;= \hat{p}_{H} - \hat{p}_{M} \\ \\
  &amp;= 0.273 - 0.229 \\ \\
  &amp;= 0.044
\end{align}`

---
## Diferencia de proporciones

Dos consideraciones importantes:

1) La diferencia de proporciones debe estar adecuadamente definida en términos de una variable dependiente y otra independiente. La razón es que, en general:

`$$\mathbb{P}(Y=1 \mid X=1) - \mathbb{P}(Y=1 \mid X=0) \neq  \mathbb{P}(X=1 \mid Y=1) - \mathbb{P}(X=1 \mid Y=0)$$`

--

En nuestro ejemplo:


```r
prop.table(ctable,2)
```

```
##         everaffair
## sex      At least once     Never
##   female     0.4800000 0.5388027
##   male       0.5200000 0.4611973
```

Si tratamos género como variable dependiente y definimos "mujeres" como la categoría de éxito, la diferencia en las proporciones es `\(\delta = 0.48 - 0.54 = -0.06\)`. 

---
## Diferencia de proporciones

2) La diferencia de proporciones es una estadística intuitiva y fácil de interpretar, pero por sí sola puede ser engañosa cuando las proporciones son ambas cercanas a cero. Consideremos los dos casos hipotéticos siguientes:

`\begin{align}
  \text{Caso 1: } p_{1a}=0.410 \text{ and } p_{1b}=0.401  \\ \\
  \text{aquí: } \delta_{1} = 0.009
\end{align}`

--
y

`\begin{align}
  \text{Caso 2: } p_{2a}=0.010 \text{ and } p_{2b}=0.001  \\ \\
  \text{aquí: } \delta_{2} = 0.009
\end{align}`

--
¿Problemas? En el caso 1 ambas porciones son, según todos los indicios, casi idénticas. En el caso 2, sin embargo, ambas proporciones son similares en términos absolutos, por muy diferentes en términos relativos: `\(0.010\)` es 10 veces mayor `\(0.001\)`.


---
### Riesgo Relativo (RR)

En casos como el descrito anteriormente el ratio entre las proporciones es una estadística más relevante. El riesgo relativo se define como:

`$$RR = \frac{\mathbb{P}(Y=1 \mid X=1)}{\mathbb{P}(Y=1 \mid X=0)}$$`

Notar que `\(RR \in [0,\infty+]\)`, donde `\(RR=1\)` indica igualdad de proporciones. 

&lt;br&gt;
--

En nuestro ejemplo, el riesgo relativo estimado es:

`\begin{align}
  \hat{RR} &amp;= \frac{\hat{p}_{H}}{\hat{p}_{M}} \\ \\
  &amp;= \frac{0.273}{0.229} = 1.19214
\end{align}`

--

La proporción de infidelidad entre los hombres es aproximadamente un 20% mayor que entre las mujeres. 

---
## Riesgo Relativo (RR)

Tres consideraciones importantes:

1) Al igual que la diferencia de proporciones, el riesgo relativo debe definirse adecuadamente en términos de una variable dependiente y otra independiente. En general:

`$$\frac{\mathbb{P}(Y=1 | X=1)}{\mathbb{P}(Y=1 | X=0)} \neq  \frac{\mathbb{P}(X=1 | Y=1) }{\mathbb{P}(X=1 | Y=0)}$$`

--

En nuestro ejemplo:


```r
prop.table(ctable,2)
```

```
##         everaffair
## sex      At least once     Never
##   female     0.4800000 0.5388027
##   male       0.5200000 0.4611973
```

Si tratamos género como variable dependiente y definimos "mujeres" como la categoría de éxito, la diferencia en las proporciones es `\(RR = 0.48/0.54 = 0.89\)`. 

---
### Riesgo Relativo (RR)

2) El riesgo relativo depende que categoría definimos cómo "éxito". En general, 


`$$\frac{\mathbb{P}(Y=1 | X=1)}{\mathbb{P}(Y=1 | X=0)} \neq \frac{\mathbb{P}(Y=0 | X=0)}{\mathbb{P}(Y=0 | X=1)}$$`
--

En nuestro ejemplo:

.pull-left[
ratio proporción infidelidad H/M
`\begin{align}
  \frac{\hat{p}_{H}}{\hat{p}_{M}} &amp;= \frac{0.273}{0.229} \\ \\
   &amp;= 1.19214
\end{align}`
]

.pull-left[
ratio proporción fidelidad M/H
`\begin{align}
  \frac{1-\hat{p}_{M}}{1-\hat{p}_{H}} &amp;= \frac{0.771}{0.727} \\ \\
   &amp;= 1.060523
\end{align}`
]


---
## Riesgo Relativo (RR)

3)  Si una de las proporciones involucradas en el cálculo es demasiado pequeña, el `\(RR\)` puede tomar valores arbitrariamente grandes o arbitrariamente pequeños. 

&lt;br&gt;

  - Ejemplo: `\(0.7/0.005 = 140\)`

--

  - En estos casos la definición de la variable dependiente/independiente, y de la la categoría de éxito afectan         
radicalmente el resultado:

    - invirtiendo la categoría de exito: `\(0.3/0.9 = 0.3\)`
    
    - invirtiendo la variable dependiente: `\(0.009/0.768=0.012\)`, u otros, dependiente de categoría de éxito
  
--

  - Problema muy común cuando se trabaja con eventos con muy baja prevalencia (ej, suicidio, covid, etc.)

---
## Odds Ratio

&lt;br&gt;

- Odds ratio ( `\(\theta\)` ) es una medida fundamental de asociación. 

- Parámetro de interés en el modelo más importante de datos categóricos: regresión logística.

--

- `\(\theta\)` está formulada para tablas de 2-por-2, pero también puede calcularse para tablas de mayor dimensión:

  - Toda tabla `\(n\)`-ways, `\(I \cdot J\)`, puede ser re-escrita como  `\((I-1) \cdot (J-1) \cdot (n-1)\)` tablas de 2-por-2.

---
### Odds

La Odds Ratio es el ratio de dos "odds", donde las "odds" una variable binaria `\(Y\)` se definen como: 

&lt;br&gt;

`\begin{align}
  \text{odds} &amp;= \frac{\mathbb{P}(Y=1)}{1-\mathbb{P}(Y=1)} \\ \\
              &amp;=  \frac{p}{1-p}
\end{align}`

&lt;br&gt;
--

Por ejemplo, si `\(Y\)` tiene una probabilidad de éxito `\(p=0.75\)`, las odds de éxito son `\(\text{odds}=\frac{0.75}{0.25} = 3\)`

- Esto significa que las "chances" éxito son 3:1


---
### Odds

las Odds son funciones de probabilidades y, por lo tanto, las probabilidades también pueden expresarse en función de las odds. Formalmente:

`$$p = \frac{\text{odds}}{1 + \text{odds}}$$`

--

Siguiendo con ejemplo anterior, si sabemos que las odds de éxito son igual a 3, entonces la probabilidad ( `\(p\)` ) de éxito es:

.pull-left[
`\begin{align}
p &amp;= \frac{3}{1 + 3} \\ \\
  &amp;= 0.75
\end{align}`
]

--

.pull-right[

.content-box-blue[
.tiny[.bold[Derivación]:
`\begin{align}
  \text{odds} &amp;= \frac{p}{1-p}  \text{  } \\ \\
  \text{odds} &amp;= \frac{1}{\frac{1}{p} - 1}  \\ \\
  \frac{1}{p} &amp;= \frac{1}{\text{odds}} + 1  \\  \\
  \frac{1}{p} &amp;= \frac{1 + \text{odds}}{\text{odds}}  \\ \\
           p  &amp;= \frac{\text{odds}}{1 + \text{odds}}
\end{align}`
]
]
]

---
## Odds Ratio

Las .bold[odds] resumen la distribución de una sola variable binaria. Para medir la asociación entre dos de estas variables en una tabla podemos calcular la .bold[odds *ratio*]. 

--

Si `\(X\)` e `\(Y\)` son las variables binarias -- independiente y dependiente -- la distribución condicional `\(f(Y \mid X)\)` se puede resumir con dos .bold[odds]:

`\begin{align}
  \text{odds}_{0} &amp;=  \frac{\mathbb{P}(Y=1 | X=0) }{1 - \mathbb{P}(Y=1 | X=0) } \quad \text{y} \\ \\
  \text{odds}_{1} &amp;=  \frac{\mathbb{P}(Y=1 | X=1) }{1 - \mathbb{P}(Y=1 | X=1) } 
\end{align}`

--

La .bold[odds *ratio*], por tanto, es:

`\begin{align}
  \theta &amp;= \frac{\text{odds}_{1}}{\text{odds}_{0}} \\ \\\
\end{align}`


---
## Odds Ratio

Volviendo a nuestro ejemplo,


```
##         everaffair
## sex      At least once     Never
##   female     0.2285714 0.7714286
##   male       0.2727273 0.7272727
```

Si `\(\hat{p}_{H}\)` es la proporción de hombres que han tenido una aventura y `\(\hat{p}_{M}\)` es la proporción de mujeres que han tenido una aventura. 


`\begin{align}
  \hat{\theta} = \frac{\text{odds}_{H}}{\text{odds}_{M}} &amp;= \\
         &amp;= \frac{\hat{p}_{H}/(1 - \hat{p}_{H})}{\hat{p}_{M}/(1 - \hat{p}_{M})} \\ \\
         &amp;= \frac{0.273/0.727}{0.229/0.771} \\ \\
         &amp;= \frac{0.38}{0.30} = 1.27
\end{align}`

---
## Odds Ratio

Dado que estas proporciones se estiman a partir de los recuentos de la tabla, `\(\theta\)` también puede expresarse de la siguiente manera, denominada .bold[cross-product ratio].

En nuestro ejemplo,

.pull-left[

```
##         everaffair
## sex      At least once Never
##   female            72   243
##   male              78   208
```
]

.pull-right[
`\begin{align}
  \hat{\theta} &amp;= \frac{\hat{p}_{H}/(1 - \hat{p}_{H})}{\hat{p}_{M}/(1 - \hat{p}_{M})} \\ \\
   &amp;= \frac{\frac{n_{21}}{n_{2+}} / \frac{n_{22}}{n_{2+}}}{\frac{n_{11}}{n_{1+}}/ \frac{n_{12}}{n_{1+} }} = \frac{n_{21}/n_{22}}{n_{11}/n_{12}}  \\ \\
   &amp;= \frac{n_{21} \cdot n_{12}}{n_{22} \cdot n_{11}} \\ \\
\end{align}`
]

--


```r
Theta = (ctable[2,1]*ctable[1,2])/(ctable[2,2]*ctable[1,1]); Theta
```

```
## [1] 1.265625
```

---
## Odds Ratio


```r
Theta = (ctable[2,1]*ctable[1,2])/(ctable[2,2]*ctable[1,1]); Theta
```

```
## [1] 1.265625
```

.bold[Interpretación]: las odds de que un hombre tenga affair son 1,27 veces mayores que las de una mujer, es decir, 27% más altas. 

Notice that:

- `\(\theta \in [0,\infty+]\)`

--

- `\(\theta=1\)` indica igualdad de odds y, por lo tanto, independencia

--

- `\(\theta &gt; 1\)` indica que el éxito es más probable para el grupo en el numerador (hombres en este caso)

--

- `\(\theta &lt; 1\)` indica que el éxito es más probable para el grupo en el denominador (mujeres en este caso)

--

- Valores lejos de 1, en cualquier dirección, representan una fuerte evidencia contra independencia

---
### Propiedades de la Odds Ratio

1) Invirtiendo el orden de las filas o columnas obtenemos el inverso la odds ratio original.


```
##         everaffair
## sex      At least once     Never
##   female     0.2285714 0.7714286
##   male       0.2727273 0.7272727
```

Si `\(\hat{p}_{H}\)` es la proporción de hombres que han tenido una aventura y `\(\hat{p}_{M}\)` es la proporción de mujeres que han tenido una aventura. 

.pull-left[
`\begin{align}
  \hat{\theta}_{HM} &amp;= \frac{\hat{p}_{H}/(1 - \hat{p}_{H})}{\hat{p}_{M}/(1 - \hat{p}_{M})} \\ \\
         &amp;= \frac{0.38}{0.30} \\ \\
         &amp;= 1.27
\end{align}`
]

.pull-right[
`\begin{align}
  \hat{\theta}_{HM} &amp;= \frac{\hat{p}_{M}/(1 - \hat{p}_{M})}{\hat{p}_{H}/(1 - \hat{p}_{H})} \\ \\
         &amp;= \frac{0.30}{0.38} \\ \\
         &amp;= 1/1.27 = 0.79
\end{align}`
]

.full-width[
Tanto `\(\theta\)` como `\(1/\theta\)` expresan el .bold[mismo grado de asociación].
]

---
### Propiedades de la Odds Ratio

2) A diferencia de las otras medidas, la odds ratio no varia en función de que  variable actúa como dependiente e independiente. En otras palabras, no es necesario identificar una variable independiente para estimar correctamente `\(\theta\)`

--

En nuestro ejemplo, tomando género como variable dependiente, donde `\(\hat{p}_{A}\)` es la probabilidad de ser hombre entre personar que han tenido un affair y `\(\hat{p}_{NA}\)` es la misma probabilidad para personas que nunca han tenido un affair, la odd-ratio de ser hombre es:

.pull-left[

```
##         everaffair
## sex      At least once     Never
##   female     0.4800000 0.5388027
##   male       0.5200000 0.4611973
```
]

.pull-right[
`\begin{align}
  \hat{\theta} &amp;= \frac{\hat{p}_{A}/(1 - \hat{p}_{A})}{\hat{p}_{NA}/(1 - \hat{p}_{NA})} \\ \\
         &amp;= \frac{0.52/0.48}{0.46/0.54} \\ \\
         &amp;= \frac{1.1}{0.85} \\ \\
         &amp;= 1.27
\end{align}`
]

---
### Propiedades de la Odds Ratio

3) La Odds Ratio es .bold[margins-free]: la odds ratio de una tabla de contingencia no se ven alteradas por el "escalamiento" (multiplicación por una constante) de filas o columnas.  

--

.pull-top[
.pull-left[
.bold[Movilidad educacional 1980]

```
##          Hij@:NU Hij@:U
## Padre:NU     160     20
## Padres:U      20     20
```
]
.pull-right[
.bold[Movilidad educacional 2020]

```
##          Hij@:NU Hij@:U
## Padre:NU     160     80
## Padres:U      20     80
```
]
]

--

.pull-bottom[
.pull-left[
- El .bold[13%] de los hijos padres sin estudios universitarios obtenía un grado universitario

- El .bold[50%] de los hijos con padres con estudios universitarios obtenía también un grado universitario
]
.pull-right[
- El .bold[33%] de los hijos padres sin estudios universitarios obtiene un grado universitario

- El .bold[80%] de los hijos con padres con estudios universitarios obtiene también un grado universitario
]
]

--

.full-width[
.bold[Titular del diario:] _Aumentan oportunidades educacionales, especialmente para la así llamada "primera generación"_
]

--

.bold[Correcto?]

---
### Propiedades de la Odds Ratio


.bold[Correcto, pero parcialmente:] el resultado refleja un .bold[cambio en la distribución marginal] de educación de los hijos, no un cambio en la asociación de las variables. 
--
 Concretamente, se duplicó la cantidad de gente que termina la universidad, independiente de su origen. 

.pull-top[

.pull-left[
.bold[Movilidad educacional 1980]

```
##          Hij@:NU Hij@:U
## Padre:NU     160     20
## Padres:U      20     20
```
]
.pull-right[
.bold[Movilidad educacional 2020]

```
##          Hij@:NU Hij@:U
## Padre:NU     160     80
## Padres:U      20     80
```
]

]

&lt;br&gt;
--

.pull-bottom[

.full-width[La odds ratio es "inmune a cambios" en la distribución marginal de las variables, capturando sólo la asociación neta entre ellas ("margin-free association")] 

.pull-left[
`\(\hat{\theta}_{1980} =  \frac{160 \cdot 20}{20 \cdot 20} = 8\)`
]
.pull-right[
`\(\hat{\theta}_{2020} =  \frac{160 \cdot 80}{20 \cdot 80} = \frac{160 \cdot (4 \cdot 20)}{20 \cdot (4 \cdot 20)} = 8\)`
]
]
 
---
### Log Odds Ratio

Como sabemos, `\(\theta \in [0,\infty+)\)`. Esto crea un problema tanto para la .bold[interpretación] como para la .bold[inferencia estadística]. Por ejemplo:

- Supongamos que la odds ratio (hombres a mujeres) de tener un affair es `\(\theta = 20\)`.
- Por ende, la odds ratio (mujeres a hombres) de tener un affair es `\(\theta^{*} = 1/ \theta = 0.05\)`. 
- Ambos resultados indican el .bold[mismo nivel de asociación], pero uno parece mucho más grande que el otro.

--

Transformando `\(\theta\)` a escala logarítmica permite mapear  `\([0,\infty+) \to (-\infty,\infty+)\)`, creando una medida de asociación  simétrica. 

`\begin{align}
  \theta &amp;=  \frac{1}{\theta^{*}}  \quad \text{entonces} \\ \\
  \log(\theta) &amp;= -1 \cdot \log(\theta^{*})
\end{align}`

--
En nuestro ejemplo:
.pull-left[

```r
log(20)
```

```
## [1] 2.995732
```
]

.pull-right[

```r
log(0.05)
```

```
## [1] -2.995732
```
]

---
### Log Odds Ratio

.pull-left[
-  `\(\log(\theta) \in (\infty-,\infty+)\)` 

- `\(\theta=0\)` indica igualdad de odds y, por lo tanto, independencia

- `\(\log(\theta) &gt; 0\)` indica que el éxito es más probable para el grupo en el numerador

- `\(\log(\theta) &lt; 0\)` indica que el éxito es más probable para el grupo en el denominador

- `\(\lvert \log(\theta) \rvert\)` indica la fuerza de la asociación entre las variables

- Valores lejos de 0, en cualquier dirección, representan fuerte evidencia contra independencia

]

.pull-right[
![](class_6_files/figure-html/unnamed-chunk-18-1.png)&lt;!-- --&gt;
]

---
### No free lunch 

![paper](paper_22table.png)


---
### Relación entre Odds ratio y Riesgo Relativo

.pull-left[
![meme_rr](or_rr.jpg)
]

--

.pull-right[
Se puede mostrar que al calcular las odds ratio entre dos grupos 1 y 2, 

`$$\theta = RR \cdot \frac{1 - p_{2}}{1 - p_{1}}$$`
&lt;br&gt;
Por tanto, si las proporciones `\(p_{1}\)` y `\(p_{2}\)` son ambas cercanas a cero, entonces `\(\theta \approx RR\)`
]

---
class: inverse, center, middle

## Inferencia para Medidas de Asociación


---
## Inferencia para medidas de Asociación

O, sobre como podemos saber si nuestros resultados no son, o no, producidos por el mero azar.

--

- Para responder esta pregunta debemos conocer la .bold[sampling distribution] de nuestro estimador, especialmente su _variabilidad_.

- Los parámetros que "generan" los datos no varían pero nuestra estimaciones si: de muestra en muestra.

--

&lt;br&gt;

.bold[Caso canónico] es el _promedio muestral_, para el cual sabemos que: `\(\bar{X} \sim \mathcal{N}(\mu,\frac{\sigma}{\sqrt{n}})\)`
 - La desviación estándar del estimador (en este caso, `\(\frac{\sigma}{\sqrt{n}}\)` ) es lo que denominamos .bold[error estándar (SE)].

--

 - Por qué? Si `\(x_1, \dots, x_n\)` son _iid_, entonces:
`\begin{align}
\mathbb{Var}\big(\bar{X}\big) &amp;= \mathbb{Var}\Big(\frac{x_{i} + ... + x_{n}}{n}\Big) = \frac{1}{n^2} \Big(\mathbb{Var}(x_{i}) + ... + \mathbb{Var}(x_{n})\Big) \\
 &amp;= \frac{1}{n^2}( \sigma^2 + ... + \sigma^2 ) = \frac{n\sigma^2}{n^2} = \frac{\sigma^2}{n} 
\end{align}`



---
### Inferencia para Diferencia de proporciones

Como recordarán de clases anteriores, asintóticamente, la "sampling distribution" de una proporción es:

`$$\hat{p} \sim \mathcal{N}(\mu,\sigma) \quad \quad \text{ donde }\mu = p \quad \text{ y }\quad \sigma = \sqrt{p(1-p)/n}$$`

--

Por tanto, la "sampling distribution" de la diferencia entre dos proporciones _independientes_,  `\(\hat{\delta} = \hat{p}_{1} - \hat{p}_{2}\)`, es:


`$$\mathcal{N}\Big(\mu_{1} = p_{1}, \sigma_{1} = \sqrt{p_{1}(1-p_{1})/n_{1}}\Big) - \mathcal{N}\Big(\mu_{2} = p_{2},  \sigma_{2} = \sqrt{p_{2}(1-p_{2})/n_{2}}\Big)$$`
--

dado que para variables independiente X e Y: 
  - `\(\mathbb{E}(X - Y)  = E(X) -  E(Y)\)` y `\(\mathbb{Var}(X - Y)  = \mathbb{Var}(X) + \mathbb{Var}(Y)\)`

entonces:

--

.content-box-blue[
`$$\hat{p}_{1} - \hat{p}_{2} \sim \mathcal{N}\Big(\mu_{\delta} = p_{1} - p_{2}, \sigma_{\delta} = \sqrt{p_{1}(1-p_{1})/n_{1} + p_{2}(1-p_{2})/n_{2}}\Big)$$`
]

---
### Inferencia para Diferencia de proporciones

.bold[Intervalo de confianza]
Podemos usar este resultado para construir un intervalo de confianza para `\(\hat{\delta} = \hat{p_{1}} - \hat{p_{2}}\)`, al (1 - `\(\alpha\)`)% de confianza. Para un nivel de significación estadística de `\(\alpha=0.05\)`,

`\begin{align}
  95\% \text{ CI}_{\hat{\delta}} &amp;= \hat{\delta} \pm 1.96 \times SE \\ \\
          &amp;= (\hat{p_{1}} - \hat{p_{2}}) \pm 1.96  \sqrt{p_{1}(1-p_{1})/n_{1} + p_{2}(1-p_{2})/n_{2}}
\end{align}`

&lt;br&gt;
.bold[Nota importante]: cuando no conocemos los _verdaderos_ parámetros reemplazamos por sus valores estimados  (en este caso, `\(\hat{p_{1}}\)` y `\(\hat{p_{2}}\)` en vez de `\(p_{1}\)` y `\(p_{2}\)`).


---
### Inferencia para Diferencia de proporciones

`$$95\% \text{ CI}_{\hat{\delta}} = (\hat{p_{1}} - \hat{p_{2}}) \pm 1.96  \sqrt{p_{1}(1-p_{1})/n_{1} + p_{2}(1-p_{2})/n_{2}}$$`

En nuestro ejemplo,

.pull-left[

```r
print(ctable)
```

```
##         everaffair
## sex      At least once Never
##   female            72   243
##   male              78   208
```
]

.pull-right[

```r
n1 = sum(ctable[2,])
n2 = sum(ctable[1,])
p1_hat = ctable[2,1]/n1
p2_hat = ctable[1,1]/n2
```
]



```r
delta_hat = p1_hat - p2_hat
se = sqrt((p1_hat*(1 - p1_hat))/n1 +  (p2_hat*(1 - p2_hat))/n2)
ci95_delta= c(ll=(delta_hat - 1.96*se), ul=(delta_hat + 1.96*se)); print(ci95_delta)
```

--

.pull-left[
Nuestro 95% CI:

```
##         ll         ul 
## -0.0252317  0.1135434
```
]

.pull-right[
Versión automática con `prop.test()` en `R`:

```
## [1] -0.02523043  0.11354212
```
]

&lt;style type="text/css"&gt;
.pull-right ~ * { clear: unset; }
.pull-right + * { clear: both; }
&lt;/style&gt;

---
### Inferencia para Diferencia de proporciones (Nota)

![overlapping](overlapping.png)
* No del todo cierto, pero tiene un punto importante

---
### Inferencia para Diferencia de proporciones (Nota)

.tiny[*asumamos mismo tamaño muestral `\(n\)` por simpleza]


.pull-left[
.bold[Intervalos de confianza sobrepuesto]

![diff](diff.png)


`\((\mu_{1} - c \cdot \sigma_{1}/\sqrt{n}) - (\mu_{2} - c \cdot \sigma_{2}/\sqrt{n}) &gt; 0 \quad ?\)` 

es decir, 

`\((\mu_{1}  - \mu_{2}) -  c \cdot (\sigma_{1}/\sqrt{n} + \sigma_{2}/\sqrt{n}) &gt; 0 \quad ?\)`
]

.pull-right[
.bold[Intervalos de confianza de differencia]

`\((\mu_{1}  - \mu_{2}) -  c \cdot \sqrt{(\sigma^{2}_{1}/n + \sigma^{2}_{2}/n)} &gt; 0 \quad ?\)`

]


---
### Inferencia para Diferencia de proporciones

.bold[Test de hipótesis]

1) ¿Cuál es la distribución de `\(\hat{p}_{1} - \hat{p}_{2}\)` bajo la nula (si la hipótesis nula es verdadera)?
  - `\(H_{0}: \tilde{\delta} = \hat{p}_{1} - \hat{p}_{2}=0\)` 

--

.content-box-blue[
`$$\tilde{\delta} =  \hat{p}_{1} - \hat{p}_{2} \sim \mathcal{N}\Big(\mu_{\delta} = 0, \sigma_{\delta} = \sqrt{p(1-p)(1/n_{1}+1/n_{2})}\Big)$$`
]


- Típicamente `\(p\)` se reemplaza por el promedio ponderado de `\(\hat{p_{1}}\)` y `\(\hat{p_{2}}\)`  

&lt;br&gt;
--

2) Calcular .bold[p-value] (2 colas)


.content-box-blue[
`$$\mathbb{P}( |\delta| &gt; \hat{\delta} \mid H_{0} \text{ es verdadera})$$`
]

---

### Inferencia para Diferencia de proporciones

.bold[Test de hipótesis]


.pull-left[
.bold[p-value] (1 cola):

`$$\mathbb{P}( \tilde{\delta} \geq \hat{\delta}=0.044 \mid H_{0})$$`

```r
p_null = p1_hat*(n1/(n1+n2)) + p2_hat*(n2/(n1+n2))
se_null = sqrt(p_null*(1 - p_null)*(1/n1 + 1/n2))
```


```r
1 - pnorm(delta_hat,mean=0,sd=se_null)
```

```
## [1] 0.1057971
```
]

--

.pull-right[
![](class_6_files/figure-html/unnamed-chunk-25-1.png)&lt;!-- --&gt;
.bold[Para ser claros:] Si `\(H_{0}\)` es cierta, nuestro `\(\hat{\delta}\)` distribuye `\(\mathcal{N}(0,\alpha=p(1-p)(1/n_{1} + 1/n_{2})\)`
]


---
### Inferencia para la Odds Ratio

- Cual es la .bold[sampling distribucion] de `\(\hat{\theta}\)`? 

--

  - Si para un proporción sabemos que `\(\hat{p} \sim \mathcal{N}(\mu,\sigma) \quad \quad \text{ donde }\mu = p \quad \text{ y }\quad \sigma = \sqrt{p(1-p)/n}\)`
  

&lt;br&gt;
La sampling distribution de `\(\hat{\theta}\)` debe ser ...

--


.pull-left[
`$$\hat{\theta} \sim \frac{\frac{\mathcal{N}(\mu_{1},\sigma_{1})}{1 - \mathcal{N}(\mu_{1},\sigma_{1})}}{\frac{\mathcal{N}(\mu_{2},\sigma_{2})}{1 - \mathcal{N}(\mu_{2},\sigma_{2})}}$$`  
]

--
.pull-right[
![meme](meme.png)

Complicado ...
]



  
  
---
### Inferencia para la Odds Ratio

- Más conveniente hacer inferencia sobre `\(\log \hat{\theta}\)`

- Usando la definición de `\(\hat{\theta}\)` como cross-product, obtenemos:


  `$$\log \hat{\theta} = \log \frac{n_{11}n_{22}}{n_{12}n_{21}} = \log n_{11} + \log n_{22} - \log n_{12} - \log n_{21}$$`

&lt;br&gt;
--

Importante resultado teórico: la sampling distribution de `\(\log \hat{\theta}\)` es _asintóticamente_ normal:

`$$\log(\hat{\theta}) \sim \mathcal{N}(\mu,\sigma)$$`
con parámetros _estimados_ por:

 - `\(\hat{\mu} = \log \hat{\theta}\)` 
 
 - `\(\hat{\sigma} = \sqrt{ \frac{1}{n_{11}} + \frac{1}{n_{12}} + \frac{1}{n_{21}} + \frac{1}{n_{22}}}\)`

---
### Inferencia para la Odds Ratio

#### Intervalo de confianza para log Odds ratio

Podemos usar este resultado para construir un intervalo de confianza para el log Odds ratio, al (1 - `\(\alpha\)`) de confianza. Para un nivel de significación estadística de `\(\alpha=0.05\)`,

`\begin{align}
  95\% \text{ CI}_{\log \hat{\theta}} &amp;= \log \hat{\theta} \pm 1.96 \cdot SE \\ \\
          &amp;= \log \hat{\theta} \pm 1.96 \cdot \sqrt{ \frac{1}{n_{11}} + \frac{1}{n_{12}} + \frac{1}{n_{21}} + \frac{1}{n_{22}} } 
\end{align}`

--

#### Intervalo de confianza para Odds ratio

Podemos obtener un intervalo de confianza estándar para la Odds ratio, al (1 - `\(\alpha\)`) de confianza tomando el exponencial del intervalo obtenido para `\(\log \hat{\theta}\)`.

`\begin{align}
  95\% \text{ CI}_{\hat{\theta}} &amp;= e^{\log \hat{\theta} \pm 1.96 \cdot \sqrt{ \frac{1}{n_{11}} + \frac{1}{n_{12}} + \frac{1}{n_{21}} + \frac{1}{n_{22}}} } 
\end{align}`

---
### Inferencia para la Odds Ratio
#### Ilustración via Monte Carlo simulation

Escenario:
- Conocemos las verdaderas probabilidad `\(Y \mid X\)` (ambas binarias).
- A partir de ellas calculamos  `\(\theta\)` y `\(\log \theta\)`.
- Estos son los parámetros "verdaderos", no estimaciones. 




```
##      [,1] [,2]
## [1,]  0.6  0.4
## [2,]  0.4  0.6
```

```
## [1] "Theta= 2.25; log Theta = 0.81"
```

---
#### Ilustración via Monte Carlo simulation


- Supón que ahora tenemos acceso a una _muestra_ de 500 casos generados con estas probabilidades 
- Creamos una tabla de contingencia y calculamos  `\(\hat{\theta}\)` y `\(\log \hat{\theta}\)`
- Éstas son nuestras estimaciones ...

--

.pull-left[

```r
set.seed(98711)
ct_sample &lt;- matrix(rpois(4,probs*500),2,2)
print(ct_sample)
```

```
##      [,1] [,2]
## [1,]  300  199
## [2,]  211  299
```
]
.pull-right[

```r
theta_hat = (ct_sample[1,1]*ct_sample[2,2])/(ct_sample[1,2]*ct_sample[2,1])
log_theta_hat = log(theta_hat)

paste0("Theta_hat= ",round(theta_hat,2),"; log Theta_hat = ",round(log_theta_hat,2))
```

```
## [1] "Theta_hat= 2.14; log Theta_hat = 0.76"
```
]

&lt;br&gt;
--

- Estos valores son similares a los "verdaderos" parámetros, pero no exactamente los mismos
- Si calculáramos `\(\hat{\theta}\)` y `\(\log \hat{\theta}\)` en una muestra diferente, obtendríamos un resultado diferente
- Si pudiéramos tomar una infinidad de muestras y repetir el proceso, observaríamos la _distribución_ de  `\(\hat{\theta}\)` y `\(\log \hat{\theta}\)`.

---
#### Ilustración via Monte Carlo simulation

- Podemos reproducir el proceso teórico de tomar infinitas muestras usando simulaciones.
- Generamos 10,000 muestras aleatorias de 500 casos, generadas con las probabilidades "verdaderas"
- Estimaremos `\(\hat{\theta_{1}} \dots \hat{\theta}_{10000}\)` y `\(\log \hat{\theta_{1}} \dots \log \hat{\theta}_{10000}\)`



```r
  set.seed(98711)
  samp_dist_theta    &lt;- NULL; samp_dist_logtheta &lt;- NULL
  
  for (i in 1:10000) {
    ct_sim &lt;- matrix(rpois(4,probs*500),2,2)
    sim_theta_hat     = (ct_sim[1,1]*ct_sim[2,2])/(ct_sim[1,2]*ct_sim[2,1])
    sim_log_theta_hat = log(sim_theta_hat)
    samp_dist_theta[i]    &lt;-  sim_theta_hat
    samp_dist_logtheta[i] &lt;-  sim_log_theta_hat
  }

samp_dist_theta %&gt;% glimpse();  samp_dist_logtheta %&gt;% glimpse()
```

```
##  num [1:10000] 2.14 2.44 2.29 2.57 2.53 ...
```

```
##  num [1:10000] 0.759 0.891 0.829 0.945 0.928 ...
```

---
#### Ilustración via Monte Carlo simulation

La distribución de nuestras estimaciones de `\(\hat{\theta}\)` y `\(\log \hat{\theta}\)` se ven así:

.pull-left[
![](class_6_files/figure-html/unnamed-chunk-30-1.png)&lt;!-- --&gt;
]

.pull-right[
![](class_6_files/figure-html/unnamed-chunk-31-1.png)&lt;!-- --&gt;
]

---
#### Ilustración via Monte Carlo simulation

--

- SE y 95% CI `\(\log \hat{\theta}\)` en simulaciones 


```r
se_logtheta = sd(samp_dist_logtheta)
ci_logtheta = quantile(samp_dist_logtheta, p=c(0.025,0.975));
print(c(SE=se_logtheta, ci_ll=ci_logtheta[1], ci_ll=ci_logtheta[2]))
```

```
##          SE  ci_ll.2.5% ci_ll.97.5% 
##   0.1304544   0.5588816   1.0744874
```

--

- SE y 95% CI `\(\log \hat{\theta}\)` basados en aproximación teórica y datos muestrales


```r
se_logtheta_hat &lt;- sqrt(1/ct_sample[1,1] + 1/ct_sample[1,2] + 1/ct_sample[2,1] + 1/ct_sample[2,2])
ci_logtheta_hat &lt;- c(log_theta_hat - 1.96*se_logtheta_hat, log_theta_hat + 1.96*se_logtheta_hat)
print(c(SE=se_logtheta_hat, ci_ll=ci_logtheta_hat[1], ci_ll=ci_logtheta_hat[2]))
```

```
##        SE     ci_ll     ci_ll 
## 0.1282274 0.5077373 1.0103889
```

---
#### Ilustración via Monte Carlo simulation


- 95% CI `\(\hat{\theta}\)` en simulaciones 


```r
ci_theta = quantile(samp_dist_theta, p=c(0.025,0.975));
print(c(ci_ll=ci_theta[1], ci_ll=ci_theta[2]))
```

```
##  ci_ll.2.5% ci_ll.97.5% 
##    1.748716    2.928491
```

--

- 95% CI `\(\hat{\theta}\)` basados en aproximación teórica y datos muestrales


```r
ci_theta_hat = exp(ci_logtheta_hat); ci_theta_hat
```

```
## [1] 1.661527 2.746669
```

- Versión automática en `R`


```r
library("DescTools")
OddsRatio(ct_sample, conf.level = 0.95, method = "mle")
```

```
## odds ratio     lwr.ci     upr.ci 
##   2.134634   1.648469   2.768875
```

--

.bold[Conclusión]: asociación entre variables es estadísticamente significativa 

---
#### Intervalo de confianza para Odds ratio

`$$95\% \text{ CI}_{\hat{\theta}} = e^{\log \hat{\theta} \pm 1.96 \cdot \sqrt{ \frac{1}{n_{11}} + \frac{1}{n_{12}} + \frac{1}{n_{21}} + \frac{1}{n_{22}}}}$$`

Aplicado a nuestro ejemplo

.pull-left[

```r
print(ctable)
```

```
##         everaffair
## sex      At least once Never
##   female            72   243
##   male              78   208
```
]

.pull-right[

```r
n11 = ctable[1,1]
n12 = ctable[1,2]
n21 = ctable[2,1]
n22 = ctable[2,2]
```
]



```r
log_theta_hat = log((n21*n12)/(n11*n22))
se = sqrt(1/n11+ 1/n12 + 1/n21 + 1/n22)
ci95_theta_hat= c(ll=exp(log_theta_hat - 1.96*se), ul=exp(log_theta_hat + 1.96*se)); print(ci95_theta_hat)
```

--

.pull-left[
Nuestro 95% CI:

```
##        ll        ul 
## 0.8742282 1.8322523
```
]

.pull-right[
Versión automática con `prop.test()` en `R`:

```
## odds ratio     lwr.ci     upr.ci 
##  1.2651182  0.8593406  1.8645659
```
]

&lt;style type="text/css"&gt;
.pull-right ~ * { clear: unset; }
.pull-right + * { clear: both; }
&lt;/style&gt;


---
### Inferencia para Riesgo Relativo

- El Riesgo Relativo es el ratio entre dos proporciones _independientes_,  `\(\hat{RR} = \hat{p}_{1}/\hat{p}_{2}\)`

- Cada `\(\hat{p} \sim \mathcal{N}(\mu,\sigma) \quad \text{ con } \quad \mu = p \quad \text{ y }\quad \sigma = \sqrt{p(1-p)/n}\)`

--

- Cual es la distribución del ratio de dos normales, `\(\mathcal{N}(\mu_{1},\sigma_{1})/ \mathcal{N}(\mu_{2},\sigma_{2})\)` ?

  -  No-negativo y muy asimétrica (cola derecha larga)

--

- Más simple (y más fácil interpretación) realizar inferencia sobre el `\(\log\hat{RR} = \log \hat{p}_{1} - \log \hat{p}_{2}\)`


&lt;br&gt;
--

- Asintóticamente `\(\log \hat{RR} \sim \mathcal{N}(\mu,\sigma)\)`, con parametros _estimados_ por: 

  -  `\(\quad \hat{\mu}: \hat{p}_{1}/\hat{p}_{2} \quad \text{ y }\quad \hat{\sigma} = \sqrt{1/n_{11} - 1/n_{1+} + 1/n_{21} - 1/n_{2+} }\)`


--

- Podemos usar este resultado para construir un intervalo de confianza para el `\(\log RR\)` al (1 - `\(\alpha\)`) de confianza.

---
### Inferencia para Riesgo Relativo

[Intergenerational Social Mobility Among the Children of Immigrants in Western Europe](https://mebucca.github.io/research/sm2geu)

.pull-left[
![paper1](SM2gEU1.png)
]

.pull-right[
![paper2](SM2gEU2.png)
]

---
class: inverse, center, middle

## Tests de Independencia 

---
### Test `\(\chi^{2}\)` de indepencia estadística 

Primer paso, testear que exista _algo_ de asociación: ¿son estas tablas _suficientemente distintas_? 



.pull-left[
.bold[Frecuencias observadas]

```
##         everaffair
## sex      At least once Never
##   female            72   243
##   male              78   208
```
]

--

.pull-right[
.bold[Frecuencias esperadas bajo independencia]

```
##        At least once   Never
## female      78.61897 236.381
## male        71.38103 214.619
```
]

Donde cada frecuencia esperada bajo independencia está dada por: `\(\tilde{n}_{ij} = n \cdot \hat{p}_{i+} \cdot  \hat{p}_{+j}\)`

--

- El test (Pearson) `\(\chi^{2}\)` mide el grado asociación en la tabla de la siguiente manera:

.content-box-blue[
`$$\text{test } \chi^{2}=\sum_{\text{all k: } i,j} \frac{(n_{ij} - \tilde{n}_{ij})^{2}}{\tilde{n}_{ij}}$$`
]

Un valor alto en el test de `\(\chi^{2}\)` sugiere que las variables no son independientes.
--
Pero, ¿cuánto es "alto"?

---
### Test `\(\chi^{2}\)` de indepencia estadística 

.bold[Nota:]
- Si `\(Z_{1}, \dots , Z_{k}\)` son variables independientes y cada `\(Z \sim \mathcal{N}(0,1)\)`, 
- Entonces la variable `\(Y = \sum_{k} Z^{2} \sim \chi^{2}_{k}\)`. `\(Y\)` distribuye `\(\chi^{2}\)` con `\(k\)` grados de libertad.

--

.bold[Heuristica:]

- Si `\(X ~ \text{Binomial(n,p)}\)` entonces, asintóticamente `\(\frac{X - np}{\sqrt{np(1-p)}}  \sim \mathcal{N}(0,1)\)`
- Por tanto, `\(\sum_{k} \frac{ (X - np)^{2} }{np(1-p)}  \sim \chi^{2}_{k}\)`  

--

.content-box-blue[
Pearson demostró que bajo `\(H_{0}, \quad\)` `\(\text{test}\chi^{2} \sim \chi_{df}^{2}\)` :
`$$\sum_{\text{all } i,j} \frac{(n_{ij} - \tilde{n}_{ij})^{2}}{\tilde{n}_{ij}} = \sum_{\text{all } i,j} \frac{(n_{ij} - n\tilde{p}_{ij})^{2}}{n\tilde{p}_{ij}} \sim \chi^{2}_{df} \quad \quad \text{donde } \quad  df= (I-1)(J-1)$$`

]
---
### Test `\(\chi^{2}\)` de indepencia estadística 

.pull-left[
.bold[Frecuencias observadas]

```
##         everaffair
## sex      At least once Never
##   female            72   243
##   male              78   208
```
]

.pull-right[
.bold[Frecuencias esperadas bajo independencia]

```
##        At least once   Never
## female      78.61897 236.381
## male        71.38103 214.619
```
]

&lt;br&gt;
--

.bold[(O-E)^2/E]


```r
(((ctable - ctable_independence)^(2))/ctable_independence) %&gt;% print()
```

```
##         everaffair
## sex      At least once     Never
##   female     0.5572541 0.1853395
##   male       0.6137589 0.2041327
```


--

.bold[Test Chi-2 : ∑ (O-E)^2/E]


```
## [1] 1.560485
```

---
### Test `\(\chi^{2}\)` de indepencia estadística 


.pull-left[
![](class_6_files/figure-html/unnamed-chunk-48-1.png)&lt;!-- --&gt;
.bold[Para ser claros:] Si la hipótesis de independencia ( `\(H_{0}\)` ) es cierta, nuestro `\(\text{test } \chi^{2}\)` distribuye `\(\chi^{2}\)` con  `\(df= (I-1)(J-1)=1\)`
]

--

.pull-right[
.bold[p-value]

`$$\mathbb{P}(\chi_{df=1}^{2} \geq \text{test } \chi^{2} \mid H_{0})$$`

```r
1- pchisq(our_chi2,df=1)
```

```
## [1] 0.2115942
```

]


---
### Test `\(\chi^{2}\)` de indepencia estadística 

.pull-left[
![](class_6_files/figure-html/unnamed-chunk-50-1.png)&lt;!-- --&gt;
.bold[Para ser claros:] Si la hipótesis de independencia ( `\(H_{0}\)` ) es cierta, nuestro `\(\text{test } \chi^{2}\)` distribuye `\(\chi^{2}\)` con  `\(df= (I-1)(J-1)=1\)`
]


.pull-right[
.bold[p-value]

`$$\mathbb{P}(\chi_{df=1}^{2} \geq \text{test } \chi^{2} \mid H_{0})$$`

```r
1- pchisq(our_chi2,df=1)
```

```
## [1] 0.2115942
```



```r
# Versión automática
chisq.test(ctable,correct = FALSE)
```

```
## 
## 	Pearson's Chi-squared test
## 
## data:  ctable
## X-squared = 1.5605, df = 1, p-value = 0.2116
```

]

---
### Test Likelihood-Ratio `\(G^{2}\)`

- .bold[Recordar]:  El MLE `\(\hat{\beta}\)` de; parámetro `\(\beta\)` es el valor que maximiza la probabilidad de ocurrencia los datos. Decimos que tal es el valor más "plausible" del parámetro 
  - Formalmente: `\(\hat{\boldsymbol{\beta}}_{MLE} = \underset{\beta}{\arg\max\ } \mathcal{L}(\boldsymbol{\beta} \mid \boldsymbol{X})\)`
  
- El estimador es una función de los datos: `\(\hat{\beta}_{MLE} = f(x_{1}, x_{2}, \dots, x_{n})\)`

&lt;br&gt;
--

.bold[Test Likelihood-Ratio] `\(G^{2}\)`


`$$G^{2} = -2 \log \Bigg(  \frac{\hat{\beta}_{MLE} \text{ bajo } H_{0}}{\hat{\beta}_{MLE} \text{ sin restricción}}\Bigg)$$`

--

- Si `\(H_{0}\)` es falsa el ratio generalmente es una número negativo muy cercano a cero. Por tanto, `\(G^2\)` será un número grande y positivo.

- `\(G^{2} \sim \chi^{2}_{df=k} \quad \quad \text{donde k = # parametros sin restricciones - # parameteros bajo } H_{0}\)`


---
### Test Likelihood-Ratio `\(G^{2}\)`


.bold[Test Likelihood-Ratio] `\(G^{2}\)`, en el caso de evaluar independencia en una tabla de contingencia 2-ways:


`$$G^{2} = -2 \log \Bigg(  \frac{\hat{\beta}_{MLE} \text{ bajo } H_{0}}{\hat{\beta}_{MLE} \text{ sin restricción}}\Bigg) = -2 \log \frac{f(\tilde{n}_{ij},  \dots, \tilde{n}_{IJ})}{f(n_{ij},  \dots, n_{IJ})}$$`


&lt;br&gt;
--
En tabla de contingencia 2-ways donde las frecuencias vienen de una distribución Multinomial, :


.content-box-blue[
Pearson demostró que bajo `\(H_{0}, \quad\)` `\(G^{2} \sim \chi_{df}^{2}\)`:

`$$2 \sum_{\text{all } i,j} n_{ij} \log \Big( \frac{n_{ij}}{\tilde{n}_{ij}} \Big) \quad \quad \text{donde } \quad  df= (I
-1)(J-1)$$`
]

--

- `\(G^{2}=0\)` cuando `\(n_{ij}=\tilde{n}_{ij} \quad \text{ para todo } i,j\)`

- `\(G^{2}\)` "grande" sugiere que variables no son independientes

---
### Test Likelihood-Ratio `\(G^{2}\)`

.pull-left[

```
## [1] 1.559105
```

![](class_6_files/figure-html/unnamed-chunk-53-1.png)&lt;!-- --&gt;
Si la hipótesis de independencia ( `\(H_{0}\)` ) es cierta, nuestro `\(\text{test } G^{2}\)` distribuye `\(\chi^{2}\)` con `\(df= (I-1)(J-1)=1\)`
]

--

.pull-right[
.bold[p-value]

`$$\mathbb{P}(\chi_{df=1}^{2} \geq \text{test } G^{2} \mid H_{0})$$`

```r
1- pchisq(our_g2,df=1)
```

```
## [1] 0.2117963
```

]

---
### Test Likelihood-Ratio `\(G^{2}\)`

.pull-left[

```
## [1] 1.559105
```

![](class_6_files/figure-html/unnamed-chunk-55-1.png)&lt;!-- --&gt;
Si la hipótesis de independencia ( `\(H_{0}\)` ) es cierta, nuestro `\(\text{test } G^{2}\)` distribuye `\(\chi^{2}\)` con `\(df= (I-1)(J-1)=1\)`
]


.pull-right[
.bold[p-value]

`$$\mathbb{P}(\chi_{df=1}^{2} \geq \text{test } G^{2} \mid H_{0})$$`

```r
1- pchisq(our_g2,df=1)
```

```
## [1] 0.2117963
```


```r
# Versión automática
library("DescTools")
GTest(ctable, correct="none")
```

```
## 
## 	Log likelihood ratio (G-test) test of independence without correction
## 
## data:  ctable
## G = 1.5591, X-squared df = 1, p-value = 0.2118
```

]

---
class: inverse, center, middle

.huge[
**Hasta la próxima clase. Gracias!**
]

&lt;br&gt;
Mauricio Bucca &lt;br&gt;
https://mebucca.github.io/ &lt;br&gt;
github.com/mebucca
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": true,
"slideNumberFormat": "%current%"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>

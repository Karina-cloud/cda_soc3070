<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Análisis de Datos Categóricos (SOL3070)</title>
    <meta charset="utf-8" />
    <meta name="author" content="  Mauricio Bucca  Profesor Asistente, Sociología UC" />
    <script src="libs/header-attrs-2.3/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" href="gentle-r.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Análisis de Datos Categóricos (SOL3070)
## Clase #6
### <br> Mauricio Bucca<br> Profesor Asistente, Sociología UC
### <a href="https://github.com/mebucca">github.com/mebucca</a>

---


class: inverse, center, middle

#Tablas de Contingencia
## Medidas de asociación

---
##  Asociación en tablas de contingencia 

Las variables de una tabla de contingencia están asociadas si la distribución condicional de las variables es distinta de su distribución marginal. Formalmente, 

&lt;br&gt;

- `\(f_{Y \mid X}(Y \mid X) \neq f_{Y}(Y)\)`

y por tanto,

- `\(f_{X \mid Y}(X \mid Y) \neq f_{X}(X)\)`


---
##  Asociación en tablas de contingencia 



Continuando con nuestro ejemplo,

.pull-left[
`\(f(\text{everaffair} \mid \text{sex})\)`

```r
prop.table(ctable,1)
```

```
##         everaffair
## sex      At least once     Never
##   female     0.2285714 0.7714286
##   male       0.2727273 0.7272727
```


`\(f(\text{everaffair})\)`

```r
prop.table(apply(ctable,2,sum))
```

```
## At least once         Never 
##      0.249584      0.750416
```

]

--

.pull-right[
Al parece que los hombres tienen una mayor probabilidad que las mujeres de haber tenido un "affair".

En lo que sigue vamos a usar este ejemplo para estudiar:

- Diferentes formas de cuantificar la asociación (o la ausencia de la misma) entre variables de una tabla de contingencia

- Evaluar si las diferencias observadas son o no más sustanciales de lo se esperaría debido al mero azar.
]

---
class: inverse, center, middle

## Tests de Independencia 

---
### Test `\(\chi^{2}\)` de indepencia estadística 

Primer paso, testear que exista _algo_ de asociación: ¿son estas tablas _suficientemente distintas_? 



.pull-left[
.bold[Frecuencias observadas]

```
##         everaffair
## sex      At least once Never
##   female            72   243
##   male              78   208
```
]

--

.pull-right[
.bold[Frecuencias esperadas bajo independencia]

```
##        At least once   Never
## female      78.61897 236.381
## male        71.38103 214.619
```
]

Donde cada frecuencia esperada bajo independencia está dada por: `\(\tilde{n}_{ij} = n \cdot \hat{p}_{i+} \cdot  \hat{p}_{+j}\)`

--

- El test (Pearson) `\(\chi^{2}\)` mide el grado asociación en la tabla de la siguiente manera:

.content-box-blue[
`$$\text{test } \chi^{2}=\sum_{\text{all k: } i,j} \frac{(n_{ij} - \tilde{n}_{ij})^{2}}{\tilde{n}_{ij}}$$`
]

Un valor alto en el test de `\(\chi^{2}\)` sugiere que las variables no son independientes.
--
Pero, ¿cuánto es "alto"?

---
### Test `\(\chi^{2}\)` de indepencia estadística 

.bold[Nota:]
- Si `\(Z_{1}, \dots , Z_{k}\)` son variables independientes y cada `\(Z \sim \mathcal{N}(0,1)\)`, 
- Entonces la variable `\(Y = \sum_{k} Z^{2} \sim \chi^{2}_{k}\)`. `\(Y\)` distribuye `\(\chi^{2}\)` con `\(k\)` grados de libertad.

--

.bold[Heuristica:]

- Si `\(X ~ \text{Binomial(n,p)}\)` entonces, asintóticamente `\(\frac{X - np}{\sqrt{np(1-p)}}  \sim \mathcal{N}(0,1)\)`
- Por tanto, `\(\sum_{k} \frac{ (X - np)^{2} }{np(1-p)}  \sim \chi^{2}_{k}\)`  

--

.content-box-blue[
Pearson probó que tambien `\(\text{test}\chi^{2} \sim \chi_{df}^{2}\)` :
`$$\sum_{\text{all } i,j} \frac{(n_{ij} - \tilde{n}_{ij})^{2}}{\tilde{n}_{ij}} = \sum_{\text{all } i,j} \frac{(n_{ij} - n\tilde{p}_{ij})^{2}}{n\tilde{p}_{ij}} \sim \chi^{2}_{df} \quad \quad \text{donde } \quad  df= (I-1)(J-1)$$`

]
---
### Test `\(\chi^{2}\)` de indepencia estadística 

.pull-left[
.bold[Frecuencias observadas]

```
##         everaffair
## sex      At least once Never
##   female            72   243
##   male              78   208
```
]

.pull-right[
.bold[Frecuencias esperadas bajo independencia]

```
##        At least once   Never
## female      78.61897 236.381
## male        71.38103 214.619
```
]

&lt;br&gt;
--

.bold[(O-E)^2/E]


```r
(((ctable - ctable_independence)^(2))/ctable_independence) %&gt;% print()
```

```
##         everaffair
## sex      At least once     Never
##   female     0.5572541 0.1853395
##   male       0.6137589 0.2041327
```


--

.bold[Test Chi-2 : ∑ (O-E)^2/E]


```
## [1] 1.560485
```

---
### Test `\(\chi^{2}\)` de indepencia estadística 


.pull-left[
![](class_6_files/figure-html/unnamed-chunk-11-1.png)&lt;!-- --&gt;
.bold[Para ser claros:] Si la hipótesis de independencia ( `\(H_{0}\)` ) es cierta, nuestro `\(\text{test } \chi^{2}\)` distribuye `\(\chi^{2}\)` con  `\(df= (I-1)(J-1)=1\)`
]

--

.pull-right[
.bold[p-value]

`$$\mathbb{P}(\chi_{df=1}^{2} \geq \text{test } \chi^{2} \mid H_{0})$$`

```r
1- pchisq(our_chi2,df=1)
```

```
## [1] 0.2115942
```

]


---
### Test `\(\chi^{2}\)` de indepencia estadística 

.pull-left[
![](class_6_files/figure-html/unnamed-chunk-13-1.png)&lt;!-- --&gt;
.bold[Para ser claros:] Si la hipótesis de independencia ( `\(H_{0}\)` ) es cierta, nuestro `\(\text{test } \chi^{2}\)` distribuye `\(\chi^{2}\)` con  `\(df= (I-1)(J-1)=1\)`
]


.pull-right[
.bold[p-value]

`$$\mathbb{P}(\chi_{df=1}^{2} \geq \text{test } \chi^{2} \mid H_{0})$$`

```r
1- pchisq(our_chi2,df=1)
```

```
## [1] 0.2115942
```



```r
# Versión automática
chisq.test(ctable,correct = FALSE)
```

```
## 
## 	Pearson's Chi-squared test
## 
## data:  ctable
## X-squared = 1.5605, df = 1, p-value = 0.2116
```

]

---
### Test Likelihood-Ratio `\(G^{2}\)`

- .bold[Recordar]:  El MLE `\(\hat{\beta}\)` de; parámetro `\(\beta\)` es el valor que maximiza la probabilidad de ocurrencia los datos. Decimos que tal es el valor más "plausible" del parámetro 
  - Formalmente: `\(\hat{\boldsymbol{\beta}}_{MLE} = \underset{\beta}{\arg\max\ } \mathcal{L}(\boldsymbol{\beta} \mid \boldsymbol{X})\)`
  
- El estimador es una función de los datos: `\(\hat{\beta}_{MLE} = f(x_{1}, x_{2}, \dots, x_{n})\)`

&lt;br&gt;
--

.bold[Test Likelihood-Ratio] `\(G^{2}\)`


`$$G^{2} = -2 \log \Bigg(  \frac{\hat{\beta}_{MLE} \text{ bajo } H_{0}}{\hat{\beta}_{MLE} \text{ sin restricción}}\Bigg)$$`

--

- Si `\(H_{0}\)` es falsa el ratio generalmente es una número negativo muy cercano a cero. Por tanto, `\(G^2\)` será un número grande y positivo.

- `\(G^{2} \sim \chi^{2}_{df=k} \quad \quad \text{donde k = # parametros sin restricciones - # parameteros bajo } H_{0}\)`


---
### Test Likelihood-Ratio `\(G^{2}\)`


.bold[Test Likelihood-Ratio] `\(G^{2}\)`, en el caso de evaluar independencia en una tabla de contingencia 2-ways:


`$$G^{2} = -2 \log \Bigg(  \frac{\hat{\beta}_{MLE} \text{ bajo } H_{0}}{\hat{\beta}_{MLE} \text{ sin restricción}}\Bigg) = -2 \log \frac{f(\tilde{n}_{ij},  \dots, \tilde{n}_{IJ})}{f(n_{ij},  \dots, n_{IJ})}$$`


&lt;br&gt;
--
En tabla de contingencia 2-ways donde las frecuencias vienen de una distribución Multinomial, :


.content-box-blue[
Pearson demostró que `\(G^{2} \sim \chi_{df}^{2}\)`:

`$$2 \sum_{\text{all } i,j} n_{ij} \log \Big( \frac{n_{ij}}{\tilde{n}_{ij}} \Big) \quad \quad \text{donde } \quad  df= (I
-1)(J-1)$$`
]

--

- `\(G^{2}=0\)` cuando `\(n_{ij}=\tilde{n}_{ij} \quad \text{ para todo } i,j\)`

- `\(G^{2}\)` "grande" sugiere que variables no son independientes

---
### Test Likelihood-Ratio `\(G^{2}\)`

.pull-left[

```
## [1] 1.559105
```

![](class_6_files/figure-html/unnamed-chunk-16-1.png)&lt;!-- --&gt;
Si la hipótesis de independencia ( `\(H_{0}\)` ) es cierta, nuestro `\(\text{test } G^{2}\)` distribuye `\(\chi^{2}\)` con `\(df= (I-1)(J-1)=1\)`
]

--

.pull-right[
.bold[p-value]

`$$\mathbb{P}(\chi_{df=1}^{2} \geq \text{test } G^{2} \mid H_{0})$$`

```r
1- pchisq(our_g2,df=1)
```

```
## [1] 0.2117963
```

]

---
### Test Likelihood-Ratio `\(G^{2}\)`

.pull-left[

```
## [1] 1.559105
```

![](class_6_files/figure-html/unnamed-chunk-18-1.png)&lt;!-- --&gt;
Si la hipótesis de independencia ( `\(H_{0}\)` ) es cierta, nuestro `\(\text{test } G^{2}\)` distribuye `\(\chi^{2}\)` con `\(df= (I-1)(J-1)=1\)`
]


.pull-right[
.bold[p-value]

`$$\mathbb{P}(\chi_{df=1}^{2} \geq \text{test } G^{2} \mid H_{0})$$`

```r
1- pchisq(our_g2,df=1)
```

```
## [1] 0.2117963
```


```r
# Versión automática
library("DescTools")
GTest(ctable, correct="none")
```

```
## 
## 	Log likelihood ratio (G-test) test of independence without correction
## 
## data:  ctable
## G = 1.5591, X-squared df = 1, p-value = 0.2118
```

]

---
class: inverse, center, middle

## Medidas de Asociación

---
##  Asociación en tablas de contingencia 

Retomando nuestro ejemplo,

.pull-left[
`\(f(\text{everaffair} \mid \text{sex})\)`

```r
prop.table(ctable,1)
```

```
##         everaffair
## sex      At least once     Never
##   female     0.2285714 0.7714286
##   male       0.2727273 0.7272727
```


`\(f(\text{everaffair})\)`

```r
prop.table(apply(ctable,2,sum))
```

```
## At least once         Never 
##      0.249584      0.750416
```

]



---

### Diferencia de proporciones

- Supongamos que tenemos una tabla de contingencia 2-ways que cruza las variables binarias `\(X\)` (independiente) y `\(Y\)` (dependiente).  Éxito se codifica con valor 1 y el fracaso con el valor 0.

- Para detectar la asociación necesitamos medir diferencias en la distribución de `\(Y\)` condicional en `\(X\)`

--
La diferencia de proporciones cuantifica estas diferencias de la siguiente manera:

`$$\delta = \mathbb{P}(Y=1 \mid X=1) - \mathbb{P}(Y=1 \mid X=0)$$`
--

Noten que `\(\delta \in [-1,1]\)` donde `\(\delta=0\)` indica proporciones iguales. 

--

Volviendo a nuestro ejemplo, `\(\hat{p}_{H}\)`, llamemos y a la proporción de hombres que han tenido una aventura y `\(\hat{p}_{M}\)` a la proporción de mujeres que han tenido una aventura. La diferencia de proporciones se define simplemente como:

`\begin{align}
  \hat{\delta} &amp;= \hat{p}_{H} - \hat{p}_{M} \\ \\
  &amp;= 0.273 - 0.229 \\ \\
  &amp;= 0.044
\end{align}`

---
### Diferencia de proporciones

Dos consideraciones importantes:

1) La diferencia de proporciones debe estar adecuadamente definida en términos de una variable dependiente y otra independiente. La razón es que, en general:

`$$\mathbb{P}(Y=1 \mid X=1) - \mathbb{P}(Y=1 \mid X=0) \neq  \mathbb{P}(X=1 \mid Y=1) - \mathbb{P}(X=1 \mid Y=0)$$`

--

En nuestro ejemplo:


```r
prop.table(ctable,2)
```

```
##         everaffair
## sex      At least once     Never
##   female     0.4800000 0.5388027
##   male       0.5200000 0.4611973
```

Si tratamos género como variable dependiente y definimos "mujeres" como la categoría de éxito, la diferencia en las proporciones es `\(\delta = 0.48 - 0.54 = -0.06\)`. 

---
### Diferencia de proporciones

2) La diferencia de proporciones es una estadística intuitiva y fácil de interpretar, pero por sí sola puede ser engañosa cuando las proporciones son ambas cercanas a cero. Consideremos los dos casos hipotéticos siguientes:

`\begin{align}
  \text{Caso 1: } p_{1a}=0.410 \text{ and } p_{1b}=0.401  \\ \\
  \text{aquí: } \delta_{1} = 0.009
\end{align}`

--
y

`\begin{align}
  \text{Caso 2: } p_{2a}=0.010 \text{ and } p_{2b}=0.001  \\ \\
  \text{aquí: } \delta_{2} = 0.009
\end{align}`

--
¿Problemas? En el caso 1 ambas porciones son, según todos los indicios, casi idénticas. En el caso 2, sin embargo, ambas proporciones son similares en términos absolutos, por muy diferentes en términos relativos: `\(0.010\)` es 10 veces mayor `\(0.001\)`.


---
### Riesgo Relativo (RR)

En casos como el descrito anteriormente el ratio entre las proporciones es una estadística más relevante. El riesgo relativo se define como:

`$$RR = \frac{\mathbb{P}(Y=1 \mid X=1)}{\mathbb{P}(Y=1 \mid X=0)}$$`

Notar que `\(RR \in [0,\infty+]\)`, donde `\(RR=1\)` indica igualdad de proporciones. 

&lt;br&gt;
--

En nuestro ejemplo, el riesgo relativo estimado es:

`\begin{align}
  \hat{RR} &amp;= \frac{\hat{p}_{H}}{\hat{p}_{M}} \\ \\
  &amp;= \frac{0.273}{0.229} = 1.19214
\end{align}`

--

La proporción de infidelidad entre los hombres es aproximadamente un 20% mayor que entre las mujeres. 

---
### Riesgo Relativo (RR)

Tres consideraciones importantes:

1) Al igual que la diferencia de proporciones, el riesgo relativo debe definirse adecuadamente en términos de una variable dependiente y otra independiente. En general:

`$$\frac{\mathbb{P}(Y=1 | X=1)}{\mathbb{P}(Y=1 | X=0)} \neq  \frac{\mathbb{P}(X=1 | Y=1) }{\mathbb{P}(X=1 | Y=0)}$$`

--

En nuestro ejemplo:


```r
prop.table(ctable,2)
```

```
##         everaffair
## sex      At least once     Never
##   female     0.4800000 0.5388027
##   male       0.5200000 0.4611973
```

Si tratamos género como variable dependiente y definimos "mujeres" como la categoría de éxito, la diferencia en las proporciones es `\(RR = 0.48/0.54 = 0.89\)`. 

---
### Riesgo Relativo (RR)

2) El riesgo relativo depende que categoría definimos cómo "éxito". En general, 


`$$\frac{\mathbb{P}(Y=1 | X=1)}{\mathbb{P}(Y=1 | X=0)} \neq \frac{\mathbb{P}(Y=0 | X=0)}{\mathbb{P}(Y=0 | X=1)}$$`
--

En nuestro ejemplo:

.pull-left[
ratio proporción infidelidad H/M
`\begin{align}
  \frac{\hat{p}_{H}}{\hat{p}_{M}} &amp;= \frac{0.273}{0.229} \\ \\
   &amp;= 1.19214
\end{align}`
]

.pull-left[
ratio proporción fidelidad M/H
`\begin{align}
  \frac{1-\hat{p}_{M}}{1-\hat{p}_{H}} &amp;= \frac{0.771}{0.727} \\ \\
   &amp;= 1.060523
\end{align}`
]


---
### Riesgo Relativo (RR)

3)  Si una de las proporciones involucradas en el cálculo es demasiado pequeña, el `\(RR\)` puede tomar valores arbitrariamente grandes o arbitrariamente pequeños. 

&lt;br&gt;

  - Ejemplo: `\(0.7/0.005 = 140\)`

--

  - En estos casos la definición de la variable dependiente/independiente, y de la la categoría de éxito afectan         
radicalmente el resultado:

    - invirtiendo la categoría de exito: `\(0.3/0.9 = 0.3\)`
    
    - invirtiendo la variable dependiente: `\(0.009/0.768=0.012\)`, u otros, dependiente de categoría de éxito
  
--

  - Problema muy común cuando se trabaja con eventos con muy baja prevalencia (ej, suicidio, covid, etc.)

---
### Odds Ratio

&lt;br&gt;

- Odds ratio ( `\(\theta\)` ) es una medida fundamental de asociación. 

- Parámetro de interés en el modelo más importante de datos categóricos: regresión logística.

--

- `\(\theta\)` está formulada para tablas de 2-por-2, pero también puede calcularse para tablas de mayor dimensión:

  - Toda tabla `\(n\)`-ways, `\(I \cdot J\)`, puede ser re-escrita como  `\((I-1) \cdot (J-1) \cdot (n-1)\)` tablas de 2-por-2.

---
#### Odds

La Odds Ratio es el ratio de dos "odds", donde las "odds" una variable binaria `\(Y\)` se definen como: 

&lt;br&gt;

`\begin{align}
  \text{odds} &amp;= \frac{\mathbb{P}(Y=1)}{1-\mathbb{P}(Y=1)} \\ \\
              &amp;=  \frac{p}{1-p}
\end{align}`

&lt;br&gt;
--

Por ejemplo, si `\(Y\)` tiene una probabilidad de éxito `\(p=0.75\)`, las odds de éxito son `\(\text{odds}=\frac{0.75}{0.25} = 3\)`

- Esto significa que las "chances" éxito son 3:1


---
#### Odds

las Odds son funciones de probabilidades y, por lo tanto, las probabilidades también pueden expresarse en función de las odds. Formalmente:

`$$p = \frac{\text{odds}}{1 + \text{odds}}$$`

--

Siguiendo con ejemplo anterior, si sabemos que las odds de éxito son igual a 3, entonces la probabilidad ( `\(p\)` ) de éxito es:

.pull-left[
`\begin{align}
p &amp;= \frac{3}{1 + 3} \\ \\
  &amp;= 0.75
\end{align}`
]

--

.pull-right[

.content-box-blue[
.tiny[.bold[Derivación]:
`\begin{align}
  \text{odds} &amp;= \frac{p}{1-p}  \text{  } \\ \\
  \text{odds} &amp;= \frac{1}{\frac{1}{p} - 1}  \\ \\
  \frac{1}{p} &amp;= \frac{1}{\text{odds}} + 1  \\  \\
  \frac{1}{p} &amp;= \frac{1 + \text{odds}}{\text{odds}}  \\ \\
           p  &amp;= \frac{\text{odds}}{1 + \text{odds}}
\end{align}`
]
]
]

---
### Odds Ratio

Las .bold[odds] resumen la distribución de una sola variable binaria. Para medir la asociación entre dos de estas variables en una tabla podemos calcular la .bold[odds *ratio*]. 

--

Si `\(X\)` e `\(Y\)` son las variables binarias -- independiente y dependiente -- la distribución condicional `\(f(Y \mid X)\)` se puede resumir con dos .bold[odds]:

`\begin{align}
  \text{odds}_{0} &amp;=  \frac{\mathbb{P}(Y=1 | X=0) }{1 - \mathbb{P}(Y=1 | X=0) } \quad \text{y} \\ \\
  \text{odds}_{1} &amp;=  \frac{\mathbb{P}(Y=1 | X=1) }{1 - \mathbb{P}(Y=1 | X=1) } 
\end{align}`

--

La .bold[odds *ratio*], por tanto, es:

`\begin{align}
  \theta &amp;= \frac{\text{odds}_{1}}{\text{odds}_{0}} \\ \\\
\end{align}`


---
### Odds Ratio

Volviendo a nuestro ejemplo,


```
##         everaffair
## sex      At least once     Never
##   female     0.2285714 0.7714286
##   male       0.2727273 0.7272727
```

Si `\(\hat{p}_{H}\)` es la proporción de hombres que han tenido una aventura y `\(\hat{p}_{M}\)` es la proporción de mujeres que han tenido una aventura. 


`\begin{align}
  \hat{\theta} = \frac{\text{odds}_{H}}{\text{odds}_{M}} &amp;= \\
         &amp;= \frac{\hat{p}_{H}/(1 - \hat{p}_{H})}{\hat{p}_{M}/(1 - \hat{p}_{M})} \\ \\
         &amp;= \frac{0.273/0.727}{0.229/0.771} \\ \\
         &amp;= \frac{0.38}{0.30} = 1.27
\end{align}`

---
### Odds Ratio

Dado que estas proporciones se estiman a partir de los recuentos de la tabla, `\(\theta\)` también puede expresarse de la siguiente manera, denominada .bold[cross-product ratio].

En nuestro ejemplo,

.pull-left[

```
##         everaffair
## sex      At least once Never
##   female            72   243
##   male              78   208
```
]

.pull-right[
`\begin{align}
  \hat{\theta} &amp;= \frac{\hat{p}_{H}/(1 - \hat{p}_{H})}{\hat{p}_{M}/(1 - \hat{p}_{M})} \\ \\
   &amp;= \frac{\frac{n_{21}}{n_{2+}} / \frac{n_{22}}{n_{2+}}}{\frac{n_{11}}{n_{1+}}/ \frac{n_{12}}{n_{1+} }} = \frac{n_{21}/n_{22}}{n_{11}/n_{12}}  \\ \\
   &amp;= \frac{n_{21} \cdot n_{12}}{n_{22} \cdot n_{11}} \\ \\
\end{align}`
]

--


```r
Theta = (ctable[2,1]*ctable[1,2])/(ctable[2,2]*ctable[1,1]); Theta
```

```
## [1] 1.265625
```

---
### Odds Ratio


```r
Theta = (ctable[2,1]*ctable[1,2])/(ctable[2,2]*ctable[1,1]); Theta
```

```
## [1] 1.265625
```

.bold[Interpretación]: las odds de que un hombre tenga affair son 1,27 veces mayores que las de una mujer, es decir, 27% más altas. 

Notice that:

- `\(\theta \in [0,\infty+]\)`

--

- `\(\theta=1\)` indica igualdad de odds y, por lo tanto, independencia

--

- `\(\theta &gt; 1\)` indica que el éxito es más probable para el grupo en el numerador (hombres en este caso)

--

- `\(\theta &lt; 1\)` indica que el éxito es más probable para el grupo en el denominador (mujeres en este caso)

--

- Valores lejos de 1, en cualquier dirección, representan una fuerte evidencia contra independencia

---
### Propiedades de la Odds Ratio

1) Invirtiendo el orden de las filas o columnas obtenemos el inverso la odds ratio original.


```
##         everaffair
## sex      At least once     Never
##   female     0.2285714 0.7714286
##   male       0.2727273 0.7272727
```

Si `\(\hat{p}_{H}\)` es la proporción de hombres que han tenido una aventura y `\(\hat{p}_{M}\)` es la proporción de mujeres que han tenido una aventura. 

.pull-left[
`\begin{align}
  \hat{\theta}_{HM} &amp;= \frac{\hat{p}_{H}/(1 - \hat{p}_{H})}{\hat{p}_{M}/(1 - \hat{p}_{M})} \\ \\
         &amp;= \frac{0.38}{0.30} \\ \\
         &amp;= 1.27
\end{align}`
]

.pull-right[
`\begin{align}
  \hat{\theta}_{HM} &amp;= \frac{\hat{p}_{M}/(1 - \hat{p}_{M})}{\hat{p}_{H}/(1 - \hat{p}_{H})} \\ \\
         &amp;= \frac{0.30}{0.38} \\ \\
         &amp;= 1/1.27 = 0.79
\end{align}`
]

.full-width[
Tanto `\(\theta\)` como `\(1/\theta\)` expresan el .bold[mismo grado de asociación].
]

---
### Propiedades de la Odds Ratio

2) A diferencia de las otras medidas, la odds ratio no varia en función de que  variable actúa como dependiente e independiente. En otras palabras, no es necesario identificar una variable independiente para estimar correctamente `\(\theta\)`

--

En nuestro ejemplo, tomando género como variable dependiente, donde `\(\hat{p}_{A}\)` es la probabilidad de ser hombre entre personar que han tenido un affair y `\(\hat{p}_{NA}\)` es la misma probabilidad para personas que nunca han tenido un affair, la odd-ratio de ser hombre es:

.pull-left[

```
##         everaffair
## sex      At least once     Never
##   female     0.4800000 0.5388027
##   male       0.5200000 0.4611973
```
]

.pull-right[
`\begin{align}
  \hat{\theta} &amp;= \frac{\hat{p}_{A}/(1 - \hat{p}_{A})}{\hat{p}_{NA}/(1 - \hat{p}_{NA})} \\ \\
         &amp;= \frac{0.52/0.48}{0.46/0.54} \\ \\
         &amp;= \frac{1.1}{0.85} \\ \\
         &amp;= 1.27
\end{align}`
]

---
### Propiedades de la Odds Ratio

3) La Odds Ratio es .bold[margins-free]: la odds ratio de una tabla de contingencia no se ven alteradas por el "escalamiento" (multiplicación por una constante) de filas o columnas.  

--

.pull-top[
.pull-left[
.bold[Movilidad educacional 1980]

```
##          Hij@:NU Hij@:U
## Padre:NU     160     20
## Padres:U      20     20
```
]
.pull-right[
.bold[Movilidad educacional 2020]

```
##          Hij@:NU Hij@:U
## Padre:NU     160     80
## Padres:U      20     80
```
]
]

--

.pull-bottom[
.pull-left[
- El .bold[13%] de los hijos padres sin estudios universitarios obtenía un grado universitario

- El .bold[50%] de los hijos con padres con estudios universitarios obtenía también un grado universitario
]
.pull-right[
- El .bold[33%] de los hijos padres sin estudios universitarios obtiene un grado universitario

- El .bold[80%] de los hijos con padres con estudios universitarios obtiene también un grado universitario
]
]

--

.full-width[
.bold[Titular del diario:] _Aumentan oportunidades educacionales, especialmente para la así llamada "primera generación"_
]

--

.bold[Correcto?]

---
### Propiedades de la Odds Ratio


.bold[Correcto, pero parcialmente:] el resultado refleja un .bold[cambio en la distribución marginal] de educación de los hijos, no un cambio en la asociación de las variables. 
--
 Concretamente, se duplicó la cantidad de gente que termina la universidad, independiente de su origen. 

.pull-top[

.pull-left[
.bold[Movilidad educacional 1980]

```
##          Hij@:NU Hij@:U
## Padre:NU     160     20
## Padres:U      20     20
```
]
.pull-right[
.bold[Movilidad educacional 2020]

```
##          Hij@:NU Hij@:U
## Padre:NU     160     80
## Padres:U      20     80
```
]

]

&lt;br&gt;
--

.pull-bottom[

.full-width[La odds ratio es "inmune a cambios" en la distribución marginal de las variables, capturando sólo la asociación neta entre ellas ("margin-free association")] 

.pull-left[
`\(\hat{\theta}_{1980} =  \frac{160 \cdot 20}{20 \cdot 20} = 8\)`
]
.pull-right[
`\(\hat{\theta}_{2020} =  \frac{160 \cdot 80}{20 \cdot 80} = \frac{160 \cdot (4 \cdot 20)}{20 \cdot (4 \cdot 20)} = 8\)`
]
]
 
---
### Log Odds Ratio

Como sabemos, `\(\theta \in [0,\infty+)\)`. Esto crea un problema tanto para la .bold[interpretación] como para la .bold[inferencia estadística]. Por ejemplo:

- Supongamos que la odds ratio (hombres a mujeres) de tener un affair es `\(\theta = 20\)`.
- Por ende, la odds ratio (mujeres a hombres) de tener un affair es `\(\theta^{*} = 1/ \theta = 0.05\)`. 
- Ambos resultados indican el .bold[mismo nivel de asociación], pero uno parece mucho más grande que el otro.

--

Transformando `\(\theta\)` a escala logarítmica permite mapear  `\([0,\infty+) \to (-\infty,\infty+)\)`, creando una medida de asociación  simétrica. 

`\begin{align}
  \theta &amp;=  \frac{1}{\theta^{*}}  \quad \text{entonces} \\ \\
  \log(\theta) &amp;= -1 \cdot \log(\theta^{*})
\end{align}`

--
En nuestro ejemplo:
.pull-left[

```r
log(20)
```

```
## [1] 2.995732
```
]

.pull-right[

```r
log(0.05)
```

```
## [1] -2.995732
```
]

---
### Log Odds Ratio

.pull-left[
-  `\(\log(\theta) \in (\infty-,\infty+)\)` 

- `\(\theta=0\)` indica igualdad de odds y, por lo tanto, independencia

- `\(\log(\theta) &gt; 0\)` indica que el éxito es más probable para el grupo en el numerador

- `\(\log(\theta) &lt; 0\)` indica que el éxito es más probable para el grupo en el denominador

- `\(\lvert \log(\theta) \rvert\)` indica la fuerza de la asociación entre las variables

- Valores lejos de 0, en cualquier dirección, representan fuerte evidencia contra independencia

]

.pull-right[
![](class_6_files/figure-html/unnamed-chunk-37-1.png)&lt;!-- --&gt;
]

---
### No free lunch 

![paper](paper_22table.png)


---
### Relación entre Odds ratio y Riesgo Relativo

.pull-left[
![meme_rr](or_rr.jpg)
]

--

.pull-right[
Se puede mostrar que al calcular las odds ratio entre dos grupos 1 y 2, 

`$$\theta = RR \cdot \frac{1 - p_{2}}{1 - p_{1}}$$`
&lt;br&gt;
Por tanto, si las proporciones `\(p_{1}\)` y `\(p_{2}\)` son ambas cercanas a cero, entonces `\(\theta \approx RR\)`
]

---
class: inverse, center, middle

## Inferencia para Medidas de Asociación


---
### Inferencia para Diferencia de proporciones

Como recordarán de clases anteriores, asintóticamente, la "sampling distribution" de una proporción es:

`$$\hat{p} \sim \mathcal{N}(\mu,\sigma) \quad \quad \text{ donde }\mu = p \quad \text{ y }\quad \sigma = \sqrt{p(1-p)/n}$$`

--

Por tanto, la "sampling distribution" de la differencia entre dos proporciones _independientes_,  `\(\delta = \hat{p}_{1} - \hat{p}_{2} \sim\)` es:


`$$\mathcal{N}\Big(\mu_{1} = p_{1}, \sigma_{1} = \sqrt{p_{1}(1-p_{1})/n_{1}}\Big) - \mathcal{N}\Big(\mu_{2} = p_{2},  \sigma_{2} = \sqrt{p_{2}(1-p_{2})/n_{2}}\Big)$$`
--

dado que para variables independiente X e Y: 
  - `\(\mathbb{E}(X - Y)  = E(X) -  E(Y)\)` y `\(\mathbb{Var}(X - Y)  = \mathbb{Var}(X) + \mathbb{Var}(Y)\)`

entonces:

--

.content-box-blue[
`$$\hat{p}_{1} - \hat{p}_{2} \sim \mathcal{N}\Big(\mu_{\delta} = p_{1} - p_{1}, \sigma_{\delta} = \sqrt{p_{1}(1-p_{1})/n_{1} + p_{2}(1-p_{2})/n_{2}}\Big)$$`
]



---
### Inferencia para la Odds Ratio

¿Como podemos saber si nuestros resultados no son producidos por el el mero azar?
--
Para responder esta pregunta debemos conocer la .bold[sampling distribution] de nuestro estimador, especialmente su _variabilidad_.

&lt;br&gt;

- El caso canónico es el promedio muestral, para el cual sabemos que: `\(\bar{X} \sim \mathcal{N}(\mu,\frac{\sigma}{\sqrt{n}})\)`
 - La desviación estándar del estimador (en este caso, `\(\frac{\sigma}{\sqrt{n}}\)` ) es lo que denominamos .bold[error estándar (SE)].

--

 - Por qué? Si `\(x_1, \dots, x_n\)` son _iid_, entonces:
`\begin{align}
\mathbb{Var}\big(\bar{X}\big) &amp;= \mathbb{Var}\Big(\frac{x_{i} + ... + x_{n}}{n}\Big) = \frac{1}{n^2} \Big(\mathbb{Var}(x_{i}) + ... + \mathbb{Var}(x_{n})\Big) \\
 &amp;= \frac{1}{n^2}( \sigma^2 + ... + \sigma^2 ) = \frac{n\sigma^2}{n^2} = \frac{\sigma^2}{n} 
\end{align}`

&lt;br&gt;
--

- Cual es la .bold[sampling distribucion] de `\(\hat{\theta}\)`?
  - Complicado ...


---
### Inferencia para la Odds Ratio

- Cual es la .bold[sampling distribucion] de `\(\hat{\theta}\)`? 

--
  - Cual es el error estándar de `\(\hat{\theta}\)`? Es decir,  `\(\mathbb{Var}\Big(\frac{n_{11}n_{22}}{n_{12}n_{21}}\Big)\)` ?
  - Complicado, función no lineal de n's.
  
--
 
- Más conveniente hacer inferencia sobre `\(\log \hat{\theta}\)`

  - `\(\log \hat{\theta} = \log \frac{n_{11}n_{22}}{n_{12}n_{21}} = \log n_{11} + \log n_{22} - \log n_{12} - \log n_{21}\)`

--

- Importante resultado teórico: la sampling distribution de `\(\log \hat{\theta}\)` es _asintóticamente_ normal:

`$$\log(\hat{\theta}) \sim \mathcal{N}(\mu,\sigma)$$`

 - `\(\mu = \log \theta\)` 
 
 - `\(\sigma = \sqrt{ \frac{1}{n_{11}} + \frac{1}{n_{12}} + \frac{1}{n_{21}} + \frac{1}{n_{22}}}\)`

---
### Inferencia para la Odds Ratio

#### Intervalo de confianza para log Odds ratio

Podemos usar este resultado para construir un intervalo de confianza para el log Odds ratio, al 95% de confianza, de la siguiente manera:

`\begin{align}
  95\% \text{ CI}_{\log \hat{\theta}} &amp;= \log \hat{\theta} \pm 1.96 \cdot SE \\ \\
          &amp;= \log \hat{\theta} \pm 1.96 \cdot \sqrt{ \frac{1}{n_{11}} + \frac{1}{n_{12}} + \frac{1}{n_{21}} + \frac{1}{n_{22}} } 
\end{align}`

#### Intervalo de confianza para Odds ratio

Podemos obtener un intervalo de confianza estándar para la Odds ratio, al 95% de confianza, de la siguiente manera:

`\begin{align}
  95\% \text{ CI}_{\hat{\theta}} &amp;= e^{\log \hat{\theta} \pm 1.96 \cdot \sqrt{ \frac{1}{n_{11}} + \frac{1}{n_{12}} + \frac{1}{n_{21}} + \frac{1}{n_{22}}} } 
\end{align}`

---
### Inferencia para la Odds Ratio
#### Ilustración via Monte Carlo simulation

Escenario:
- Tenemos datos de población de las variables binarias `\(X\)` e `\(Y\)`.
- Creamos tabla de contingencia y calculamos  `\(\theta\)` y `\(\log \theta\)`.
- Éstos son los parámetros "verdaderos", no estimaciones. 




```r
ct &lt;- table(population_data$x,population_data$y); print(ct)
```

```
##    
##       0   1
##   0 280 270
##   1 180 270
```

```r
theta     = (ct[1,1]*ct[2,2])/(ct[1,2]*ct[2,1])
log_theta = log(theta)

paste0("Theta= ",round(theta,2),"; log Theta = ",round(log_theta,2))
```

```
## [1] "Theta= 1.56; log Theta = 0.44"
```

---
#### Ilustración via Monte Carlo simulation


- Supón que ahora  tenemos acceso a una muestra aleatoria de los datos poblacionales
- Creamos una tabla de contingencia y calculamos  `\(\hat{\theta}\)` y `\(\log \hat{\theta}\)`
- Éstas son nuestras estimaciones ...

--

.pull-left[

```r
set.seed(1234)
sample_data &lt;- sample_n(population_data, size=500, replace=TRUE)
ct_sample &lt;- table(sample_data$x,sample_data$y); print(ct_sample)
```

```
##    
##       0   1
##   0 155 131
##   1  85 129
```
]
.pull-right[

```r
theta_hat = (ct_sample[1,1]*ct_sample[2,2])/(ct_sample[1,2]*ct_sample[2,1])
log_theta_hat = log(theta_hat)

paste0("Theta_hat= ",round(theta_hat,2),"; log Theta_hat = ",round(log_theta_hat,2))
```

```
## [1] "Theta_hat= 1.8; log Theta_hat = 0.59"
```
]

&lt;br&gt;
--

- Estos valores son similares a los "verdaderos" parámetros, pero no exactamente los mismos
- Si calculáramos `\(\hat{\theta}\)` y `\(\log \hat{\theta}\)` en una muestra diferente, obtendríamos un resultado diferente
- Si pudiéramos tomar una infinidad de muestras y repetir el proceso, observaríamos la _distribución_ de  `\(\hat{\theta}\)` y `\(\log \hat{\theta}\)`.

---
#### Ilustración via Monte Carlo simulation

- Podemos reproducir el proceso teórico de tomar infinitas muestras usando simulaciones.
- Tomas 5000 muestras aleatorias de los datos poblacionales
- Estimaremos `\(\hat{\theta_{1}} \dots \hat{\theta}_{5000}\)` y `\(\log \hat{\theta_{1}} \dots \log \hat{\theta}_{5000}\)`



```r
  samp_dist_theta    &lt;- NULL; samp_dist_logtheta &lt;- NULL
  
  for (i in 1:5000) {
    sample_data &lt;- sample_n(population_data, size=500, replace=TRUE)
    ct_sample &lt;- table(sample_data$x,sample_data$y)
    theta_hat     = (ct_sample[1,1]*ct_sample[2,2])/(ct_sample[1,2]*ct_sample[2,1])
    log_theta_hat = log(theta_hat)
    samp_dist_theta[i]    &lt;-  theta_hat
    samp_dist_logtheta[i] &lt;-  log_theta_hat
  }

samp_dist_theta %&gt;% glimpse();  samp_dist_logtheta %&gt;% glimpse()
```

```
##  num [1:5000] 1.65 1.62 1.51 1.46 1.3 ...
```

```
##  num [1:5000] 0.499 0.483 0.409 0.381 0.26 ...
```

---
#### Ilustración via Monte Carlo simulation

La distribución de nuestras estimaciones de `\(\hat{\theta}\)` y `\(\log \hat{\theta}\)` se ven así:

.pull-left[
![](class_6_files/figure-html/unnamed-chunk-43-1.png)&lt;!-- --&gt;
]

.pull-right[
![](class_6_files/figure-html/unnamed-chunk-44-1.png)&lt;!-- --&gt;
]

---
#### Ilustración via Monte Carlo simulation

--

- SE y 95% CI `\(\log \hat{\theta}\)` en simulaciones 


```r
se_logtheta = sd(samp_dist_logtheta)
ci_logtheta = quantile(samp_dist_logtheta, p=c(0.025,0.975));
print(c(SE=se_logtheta, ci_ll=ci_logtheta[1], ci_ll=ci_logtheta[2]))
```

```
##          SE  ci_ll.2.5% ci_ll.97.5% 
##  0.18032386  0.08890733  0.79204059
```

--

- SE y 95% CI `\(\log \hat{\theta}\)` basados en aproximación teórica y datos muestrales


```r
se_logtheta_hat &lt;- sqrt(1/ct_sample[1,1] + 1/ct_sample[1,2] + 1/ct_sample[2,1] + 1/ct_sample[2,2])
ci_logtheta_hat &lt;- c(log_theta_hat - 1.96*se_logtheta_hat, log_theta_hat + 1.96*se_logtheta_hat)
print(c(SE=se_logtheta_hat, ci_ll=ci_logtheta_hat[1], ci_ll=ci_logtheta_hat[2]))
```

```
##         SE      ci_ll      ci_ll 
## 0.18287547 0.06625061 0.78312244
```

---
#### Ilustración via Monte Carlo simulation


- 95% CI `\(\hat{\theta}\)` en simulaciones 


```r
ci_theta = quantile(samp_dist_theta, p=c(0.025,0.975));
print(c(ci_ll=ci_theta[1], ci_ll=ci_theta[2]))
```

```
##  ci_ll.2.5% ci_ll.97.5% 
##    1.092979    2.207897
```

&lt;br&gt;
--

- 95% CI `\(\hat{\theta}\)` basados en aproximación teórica y datos muestrales


```r
ci_theta_hat = exp(ci_logtheta_hat); ci_theta_hat
```

```
## [1] 1.068494 2.188294
```

&lt;br&gt;
--

.bold[Conclusión]: asociación entre variables es estadísticamente significativa 

---
class: inverse, center, middle

.huge[
**Hasta la próxima clase. Gracias!**
]

&lt;br&gt;
Mauricio Bucca &lt;br&gt;
https://mebucca.github.io/ &lt;br&gt;
github.com/mebucca




    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": true,
"slideNumberFormat": "%current%"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
